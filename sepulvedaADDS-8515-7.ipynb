{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V6E1",
      "authorship_tag": "ABX9TyP9AgpUoISPjCoPx8TRvnJC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alfredqbit/NU-DDS-8515/blob/main/sepulvedaADDS-8515-7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 7: Analyze Ecological Data using Multivariate Regression and CCA\n",
        "\n",
        "Jupyter Python notebook:\n",
        "\n",
        " - Downloads the dune and dune.env data from public R-universe/CRAN mirrors or GitHub-like sources.\n",
        "\n",
        " - Computes richness and Shannon diversity.\n",
        "\n",
        " - Builds multivariate regression, ridge, and multitask lasso pipelines.\n",
        "\n",
        " - Runs CCA using scikit-bio.\n",
        "\n",
        " - Exports all key plots as PNGs into a figures/ subdirectory with the filenames referenced in the LaTeX."
      ],
      "metadata": {
        "id": "QyfMZuXrpTT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import io # Added by the user\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression, RidgeCV, MultiTaskLassoCV\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "# Perform a clean and ordered installation to resolve deep dependency conflicts\n",
        "#!pip uninstall -y requests urllib3 chardet idna beautifulsoup4 tqdm six\n",
        "#!pip install six\n",
        "#!pip install requests\n",
        "# You will need scikit-bio:\n",
        "!pip install scikit-bio\n",
        "from skbio.stats.ordination import cca\n",
        "\n",
        "# Plot style\n",
        "plt.rcParams[\"figure.figsize\"] = (7, 5)\n",
        "plt.rcParams[\"axes.grid\"] = True\n",
        "\n",
        "FIG_DIR = Path(\"figures\")\n",
        "FIG_DIR.mkdir(exist_ok=True)"
      ],
      "metadata": {
        "id": "OgeRoh6Ap8lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load dune data from R-universe"
      ],
      "metadata": {
        "id": "GyAEKOfrqAI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dune_data():\n",
        "   # Load dune species and environmental data by embedding it directly.\n",
        "\n",
        "   # Returns\n",
        "\n",
        "   # dune : pd.DataFrame\n",
        "   #     Species abundance table (sites x species).\n",
        "   # dune_env : pd.DataFrame\n",
        "   #     Environmental variables (sites x env variables).\n",
        "\n",
        "   # Ensure expected columns\n",
        "   # (dune: 30 species; dune_env: A1, Moisture, Management, Use, Manure)\n",
        "    import rpy2.robjects as ro\n",
        "    from rpy2.robjects.packages import importr\n",
        "    from rpy2.robjects import pandas2ri\n",
        "\n",
        "# Import the R 'utils' package for certain functions (like data() or install.packages())\n",
        "    utils = importr('utils')\n",
        "\n",
        "# Import the R package containing the 'dune' data (e.g., 'vegan')\n",
        "# rpy2 automatically translates R's dot notation to Python's underscore notation\n",
        "# but the package name itself is imported directly\n",
        "    utils.install_packages('vegan') # Ensure vegan is installed\n",
        "\n",
        "# Load the 'dune' and 'dune.env' datasets explicitly from the 'vegan' package\n",
        "    ro.r('data(\"dune\", package=\"vegan\")')\n",
        "    ro.r('data(\"dune.env\", package=\"vegan\")')\n",
        "\n",
        "# Access the loaded R data frame from Python's global environment\n",
        "    dune_r_dataframe = ro.r['dune']\n",
        "    dune_env_r_dataframe = ro.r['dune.env']\n",
        "\n",
        "# Convert R data frame to a pandas DataFrame\n",
        "    pandas2ri.activate()\n",
        "    dune_pandas_df = pandas2ri.rpy2py(dune_r_dataframe)\n",
        "    dune_env_pandas_df = pandas2ri.rpy2py(dune_env_r_dataframe)\n",
        "\n",
        "    return dune_pandas_df, dune_env_pandas_df\n",
        "\n",
        "\n",
        "dune, dune_env = load_dune_data()\n",
        "# check for missing values in datasets\n",
        "print(\"Missing values in dune species data:\")\n",
        "print(dune.isnull().sum())\n",
        "print(\"\\nMissing values in dune environmental data:\")\n",
        "print(dune_env.isnull().sum())\n",
        "# display dataset head\n",
        "display(dune.head())\n",
        "display(dune_env.head())"
      ],
      "metadata": {
        "id": "1ConkMUWqDqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Derive richness and Shannon diversity, build MR dataset"
      ],
      "metadata": {
        "id": "hcLnCZTwqHYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_diversity_metrics(dune_df: pd.DataFrame) -> pd.DataFrame:\n",
        "\n",
        "    #Compute species richness and Shannon diversity for each site.\n",
        "\n",
        "    #Parameters\n",
        "    #----------\n",
        "    #dune_df : DataFrame\n",
        "    #    Species abundance / cover matrix (sites x species).\n",
        "\n",
        "    #Returns\n",
        "    #-------\n",
        "    #metrics : DataFrame\n",
        "    #    Columns: 'richness', 'shannon'.\n",
        "\n",
        "    # Convert cover classes to numeric counts (assume >0 = present)\n",
        "    abundance = dune_df.astype(float).clip(lower=0.0)\n",
        "\n",
        "    # Richness: number of species with positive abundance\n",
        "    richness = (abundance > 0).sum(axis=1)\n",
        "\n",
        "    # Shannon: H' = -sum p * log p\n",
        "    row_sums = abundance.sum(axis=1)\n",
        "    # Avoid /0 by dropping all-zero rows (shouldn't exist here)\n",
        "    valid = row_sums > 0\n",
        "    p = abundance[valid].div(row_sums[valid], axis=0)\n",
        "    shannon = pd.Series(0.0, index=abundance.index)\n",
        "    shannon[valid] = -(p * np.log(p.replace(0, np.nan))).sum(axis=1).fillna(0.0)\n",
        "\n",
        "    metrics = pd.DataFrame({\n",
        "        \"richness\": richness,\n",
        "        \"shannon\": shannon\n",
        "    }, index=dune_df.index)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "div_metrics = compute_diversity_metrics(dune)\n",
        "display(div_metrics.head())"
      ],
      "metadata": {
        "id": "heFZsbrJqJ-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation matrix and heatmap (saved for LaTeX Figure mr_corr_matrix)"
      ],
      "metadata": {
        "id": "U1AX0EWMqMtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For correlations, convert ordered factors to codes\n",
        "env_for_corr = dune_env.copy()\n",
        "for col in [\"Moisture\", \"Use\", \"Manure\", \"Management\"]:\n",
        "    if col in env_for_corr.columns:\n",
        "        env_for_corr[col] = env_for_corr[col].astype(\"category\").cat.codes\n",
        "\n",
        "corr_df = pd.concat([div_metrics, env_for_corr], axis=1)\n",
        "corr = corr_df.corr()\n",
        "\n",
        "plt.figure()\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True)\n",
        "plt.title(\"Correlation matrix: diversity metrics and environmental variables\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"mr_corr_matrix.png\", dpi=300)\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "4DkrXN7EqOvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess data, build multivariate regression + regularized models"
      ],
      "metadata": {
        "id": "IGG2wUqbqRAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare MR design matrix X and response Y\n",
        "X_env = dune_env.copy()\n",
        "numeric_features = [\"A1\"]\n",
        "categorical_features = [\"Moisture\", \"Management\", \"Use\", \"Manure\"]\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), numeric_features),\n",
        "        (\"cat\", OneHotEncoder(drop=\"first\", sparse_output=False), categorical_features),\n",
        "    ]\n",
        ")\n",
        "\n",
        "Y = div_metrics[[\"richness\", \"shannon\"]].values\n",
        "\n",
        "# OLS multivariate regression\n",
        "ols_pipeline = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocess),\n",
        "        (\"reg\", LinearRegression())\n",
        "    ]\n",
        ")\n",
        "\n",
        "ols_pipeline.fit(X_env, Y)\n",
        "Y_hat_ols = ols_pipeline.predict(X_env)\n",
        "\n",
        "# Metrics per response\n",
        "results_mr = {}\n",
        "for i, name in enumerate([\"richness\", \"shannon\"]):\n",
        "    y_true = Y[:, i]\n",
        "    y_pred = Y_hat_ols[:, i]\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "    n, p = X_env.shape\n",
        "    # crude adjusted R^2 using number of encoded cols\n",
        "    X_trans = ols_pipeline.named_steps[\"preprocess\"].transform(X_env)\n",
        "    p_eff = X_trans.shape[1]\n",
        "    adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p_eff - 1)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    results_mr[name] = {\"R2\": r2, \"Adj_R2\": adj_r2, \"MSE\": mse}\n",
        "\n",
        "results_mr"
      ],
      "metadata": {
        "id": "3yxQsYLEqTc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Residual diagnostics (richness + Shannon) → PNGs"
      ],
      "metadata": {
        "id": "z7DTFiaYqWl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def diagnostic_plots(y_true, y_pred, base_name: str):\n",
        "    resid = y_true - y_pred\n",
        "\n",
        "    # Q-Q plot\n",
        "    from scipy import stats\n",
        "    fig, ax = plt.subplots()\n",
        "    stats.probplot(resid, dist=\"norm\", plot=ax)\n",
        "    ax.set_title(f\"Q-Q plot of residuals ({base_name})\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(FIG_DIR / f\"mr_resid_{base_name}_qq.png\", dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # Residuals vs fitted\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.scatter(y_pred, resid)\n",
        "    ax.axhline(0, color=\"black\", linewidth=1)\n",
        "    ax.set_xlabel(\"Fitted values\")\n",
        "    ax.set_ylabel(\"Residuals\")\n",
        "    ax.set_title(f\"Residuals vs fitted ({base_name})\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(FIG_DIR / f\"mr_resid_{base_name}_fitted.png\", dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "diagnostic_plots(Y[:, 0], Y_hat_ols[:, 0], base_name=\"richness\")\n",
        "diagnostic_plots(Y[:, 1], Y_hat_ols[:, 1], base_name=\"shannon\")"
      ],
      "metadata": {
        "id": "re4FB6uQqYdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ridge and multitask lasso, coefficient comparison plot"
      ],
      "metadata": {
        "id": "PIjIiVxxqcPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformed design once (pipeline handles it but we need feature names)\n",
        "preprocess.fit(X_env)\n",
        "X_trans = preprocess.transform(X_env)\n",
        "\n",
        "# Feature names from the preprocessor\n",
        "num_names = numeric_features\n",
        "cat_names = list(\n",
        "    preprocess.named_transformers_[\"cat\"].get_feature_names_out(categorical_features)\n",
        ")\n",
        "feature_names = num_names + cat_names\n",
        "\n",
        "# Ridge (multi-output)\n",
        "alphas = np.logspace(-3, 3, 7)\n",
        "ridge = RidgeCV(alphas=alphas)\n",
        "ridge.fit(X_trans, Y)\n",
        "B_ridge = ridge.coef_  # shape (n_targets, n_features)\n",
        "\n",
        "# Multitask lasso (joint sparsity over responses)\n",
        "lasso = MultiTaskLassoCV(\n",
        "    alphas=np.logspace(-3, 1, 20),\n",
        "    cv=min(5, len(X_trans)),\n",
        "    random_state=42\n",
        ")\n",
        "lasso.fit(X_trans, Y)\n",
        "B_lasso = lasso.coef_  # shape (n_targets, n_features)\n",
        "\n",
        "# OLS coefficients in transformed space\n",
        "ols = ols_pipeline.named_steps[\"reg\"]\n",
        "B_ols = ols.coef_  # (n_targets, n_features)\n",
        "\n",
        "# Build tidy coefficient table\n",
        "coef_df = pd.DataFrame({\n",
        "    \"feature\": feature_names,\n",
        "    \"OLS_richness\": B_ols[0, :],\n",
        "    \"OLS_shannon\": B_ols[1, :],\n",
        "    \"Ridge_richness\": B_ridge[0, :],\n",
        "    \"Ridge_shannon\": B_ridge[1, :],\n",
        "    \"Lasso_richness\": B_lasso[0, :],\n",
        "    \"Lasso_shannon\": B_lasso[1, :],\n",
        "})\n",
        "\n",
        "coef_long = coef_df.melt(\n",
        "    id_vars=\"feature\",\n",
        "    var_name=\"model_response\",\n",
        "    value_name=\"coef\"\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(\n",
        "    data=coef_long,\n",
        "    x=\"feature\",\n",
        "    y=\"coef\",\n",
        "    hue=\"model_response\"\n",
        ")\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Coefficient comparison: OLS, Ridge, Multitask Lasso\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"mr_coeffs_comparison.png\", dpi=300)\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "CRb5SmMeqe8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CCA with scikit-bio"
      ],
      "metadata": {
        "id": "5QKK9yQQqh-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_cca(dune_df: pd.DataFrame, dune_env_df: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Run canonical correspondence analysis using scikit-bio.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ord_res : OrdinationResults\n",
        "    species_scores : DataFrame\n",
        "    site_scores : DataFrame\n",
        "    env_scores : DataFrame\n",
        "    \"\"\"\n",
        "    # Species matrix: fill NaNs with 0 as cca cannot handle them\n",
        "    Y_cca = dune_df.fillna(0).copy()\n",
        "\n",
        "    # Before filtering, identify and report rows with only zeros\n",
        "    rows_all_zeros_before_filter = (Y_cca.sum(axis=1) == 0)\n",
        "    print(f\"Number of rows with all zeros in Y_cca before filtering: {rows_all_zeros_before_filter.sum()}\")\n",
        "\n",
        "    # Remove rows (sites) with only 0's from species data and corresponding environmental data\n",
        "    non_empty_sites = Y_cca.sum(axis=1) > 0\n",
        "    Y_cca = Y_cca[non_empty_sites]\n",
        "    dune_env_df_filtered = dune_env_df[non_empty_sites]\n",
        "\n",
        "    # After filtering, verify no rows have only zeros\n",
        "    rows_all_zeros_after_filter = (Y_cca.sum(axis=1) == 0)\n",
        "    if rows_all_zeros_after_filter.any():\n",
        "        print(\"WARNING: Y_cca still contains rows with all zeros after filtering!\")\n",
        "        print(Y_cca[rows_all_zeros_after_filter])\n",
        "    else:\n",
        "        print(\"Y_cca successfully filtered; no rows with all zeros found.\")\n",
        "\n",
        "    # Further filter out species (columns) with all zeros from Y_cca\n",
        "    non_empty_species = Y_cca.sum(axis=0) > 0\n",
        "    Y_cca = Y_cca.loc[:, non_empty_species]\n",
        "    print(f\"Number of species with all zeros removed: {(~non_empty_species).sum()}\")\n",
        "    print(f\"Y_cca shape after species filtering: {Y_cca.shape}\")\n",
        "\n",
        "    # Environmental matrix: dummy-coded, use filtered env data\n",
        "    X_cca = pd.get_dummies(dune_env_df_filtered, drop_first=True)\n",
        "\n",
        "    ord_res = cca(Y_cca, X_cca)\n",
        "    species_scores = ord_res.features.iloc[:, :2]\n",
        "    site_scores = ord_res.samples.iloc[:, :2]\n",
        "    env_scores = ord_res.biplot_scores.iloc[:, :2]\n",
        "\n",
        "    return ord_res, species_scores, site_scores, env_scores, X_cca.columns\n",
        "\n",
        "\n",
        "ord_res, species_scores, site_scores, env_scores, env_names = run_cca(dune, dune_env)\n",
        "ord_res"
      ],
      "metadata": {
        "id": "N4fWCHK0qkvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CCA eigenvalues plot"
      ],
      "metadata": {
        "id": "PVZdseVGqoCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eigvals = ord_res.eigvals\n",
        "prop = eigvals / eigvals.sum()\n",
        "cumprop = prop.cumsum()\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.bar(range(1, len(eigvals) + 1), eigvals, label=\"Eigenvalues\")\n",
        "ax1.set_xlabel(\"CCA axis\")\n",
        "ax1.set_ylabel(\"Eigenvalue\")\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(range(1, len(eigvals) + 1), cumprop, marker=\"o\", color=\"tab:red\", label=\"Cumulative proportion\")\n",
        "ax2.set_ylabel(\"Cumulative proportion of constrained inertia\")\n",
        "\n",
        "lines, labels = ax1.get_legend_handles_labels()\n",
        "lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "ax1.legend(lines + lines2, labels + labels2, loc=\"upper right\")\n",
        "\n",
        "plt.title(\"CCA eigenvalues and cumulative constrained inertia\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"cca_eigenvalues.png\", dpi=300)\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "5TuzKVPTXEJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CCA biplots (sites + env; species)"
      ],
      "metadata": {
        "id": "uQpXKA3yqthl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Site scores colored by Management, with env vectors\n",
        "cca_df_sites = site_scores.copy()\n",
        "\n",
        "# Only proceed with site biplot if at least one CCA component is available\n",
        "if len(site_scores.columns) >= 1:\n",
        "    cca_df_sites[\"Management\"] = dune_env[\"Management\"].astype(str)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(7, 6))\n",
        "    if len(site_scores.columns) >= 2:\n",
        "        # Plot 2D biplot if at least two components are available\n",
        "        for mtype, sub in cca_df_sites.groupby(\"Management\"):\n",
        "            ax.scatter(sub.iloc[:, 0], sub.iloc[:, 1], label=mtype)\n",
        "        ax.set_xlabel(\"CCA1\")\n",
        "        ax.set_ylabel(\"CCA2\")\n",
        "        ax.set_title(\"CCA site scores (colored by management)\")\n",
        "\n",
        "        # Environmental vectors from origin if at least two components are available\n",
        "        if len(env_scores.columns) >= 2:\n",
        "            for name, (xv, yv) in env_scores.iterrows():\n",
        "                ax.arrow(0, 0, xv, yv, head_width=0.05, length_includes_head=True, color=\"black\")\n",
        "                ax.text(xv * 1.05, yv * 1.05, name, fontsize=9)\n",
        "        else:\n",
        "            print(\"Warning: Not enough CCA components for 2D environmental vectors on site biplot.\")\n",
        "\n",
        "    else:\n",
        "        # Plot 1D if only one component is available\n",
        "        print(\"Warning: Only 1 CCA component available for site scores. Plotting 1D.\")\n",
        "        for mtype, sub in cca_df_sites.groupby(\"Management\"):\n",
        "            ax.scatter(sub.iloc[:, 0], np.zeros_like(sub.iloc[:, 0]), label=mtype)\n",
        "        ax.set_xlabel(\"CCA1\")\n",
        "        ax.set_ylabel(\"\") # No CCA2 axis\n",
        "        ax.set_title(\"CCA site scores (colored by management - 1D)\")\n",
        "\n",
        "    ax.legend(title=\"Management\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(FIG_DIR / \"cca_sites_biplot_management.png\", dpi=300)\n",
        "    plt.close()\n",
        "else:\n",
        "    print(\"Warning: No CCA components available for site scores. Skipping site biplot.\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# Species scores\n",
        "# Only proceed with species biplot if at least one CCA component is available\n",
        "if len(species_scores.columns) >= 1:\n",
        "    fig, ax = plt.subplots(figsize=(7, 6))\n",
        "    if len(species_scores.columns) >= 2:\n",
        "        # Plot 2D biplot if at least two components are available\n",
        "        ax.scatter(species_scores.iloc[:, 0], species_scores.iloc[:, 1], s=20)\n",
        "        for sp, (xs, ys) in species_scores.iterrows():\n",
        "            ax.text(xs, ys, sp, fontsize=7)\n",
        "        ax.set_xlabel(\"CCA1\")\n",
        "        ax.set_ylabel(\"CCA2\")\n",
        "        ax.set_title(\"CCA species scores\")\n",
        "    else:\n",
        "        # Plot 1D if only one component is available\n",
        "        print(\"Warning: Only 1 CCA component available for species scores. Plotting 1D.\")\n",
        "        ax.scatter(species_scores.iloc[:, 0], np.zeros_like(species_scores.iloc[:, 0]), s=20)\n",
        "        for sp, xs in species_scores.iloc[:, 0].items():\n",
        "            ax.text(xs, 0, sp, fontsize=7)\n",
        "        ax.set_xlabel(\"CCA1\")\n",
        "        ax.set_ylabel(\"\") # No CCA2 axis\n",
        "        ax.set_title(\"CCA species scores (1D)\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(FIG_DIR / \"cca_species_biplot.png\", dpi=300)\n",
        "    plt.close()\n",
        "else:\n",
        "    print(\"Warning: No CCA components available for species scores. Skipping species biplot.\")\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "4GB2gVVGqvwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c88ef81"
      },
      "source": [
        "\n",
        "Use statsmodels package to obtain F-score, p-values, AIC anmd BIC values for OLS fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c91bee1"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# --- 1. Calculate Diversity Metrics ---\n",
        "# Richness: Count of species with abundance > 0\n",
        "richness = (dune > 0).sum(axis=1)\n",
        "\n",
        "# Shannon: H' = -sum(p * ln(p))\n",
        "# Calculate proportional abundance\n",
        "total_abundance = dune.sum(axis=1)\n",
        "p = dune.div(total_abundance, axis=0)\n",
        "# Calculate Shannon index (handling log(0) by replacing 0 with 1, since ln(1)=0)\n",
        "shannon = -(p * np.log(p.replace(0, 1))).sum(axis=1)\n",
        "\n",
        "# Combine into a DataFrame (optional, but good for inspection)\n",
        "diversity_df = pd.DataFrame({'richness': richness, 'shannon': shannon})\n",
        "\n",
        "# --- 2. Preprocess Environmental Data ---\n",
        "numeric_features = [\"A1\"]\n",
        "categorical_features = [\"Moisture\", \"Management\", \"Use\", \"Manure\"]\n",
        "\n",
        "# Define the ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), numeric_features),\n",
        "        (\"cat\", OneHotEncoder(drop=\"first\", sparse_output=False), categorical_features),\n",
        "    ],\n",
        "    verbose_feature_names_out=False  # To keep feature names simple if supported\n",
        ")\n",
        "\n",
        "# Fit and transform the data\n",
        "X_transformed = preprocessor.fit_transform(dune_env)\n",
        "\n",
        "# Retrieve feature names\n",
        "try:\n",
        "    # Recent sklearn versions\n",
        "    feature_names = preprocessor.get_feature_names_out()\n",
        "except AttributeError:\n",
        "    # Older sklearn versions might need a workaround or get_feature_names()\n",
        "    feature_names = (numeric_features +\n",
        "                     list(preprocessor.named_transformers_[\"cat\"].get_feature_names_out(categorical_features)))\n",
        "\n",
        "# Create DataFrame with feature names and add constant (intercept)\n",
        "X_sm = pd.DataFrame(X_transformed, columns=feature_names, index=dune_env.index)\n",
        "X_sm = sm.add_constant(X_sm)\n",
        "\n",
        "# --- 3. OLS Regression for Richness ---\n",
        "print(\"OLS Regression Results for Species Richness:\")\n",
        "model_richness = sm.OLS(diversity_df['richness'], X_sm)\n",
        "results_richness = model_richness.fit()\n",
        "print(results_richness.summary())\n",
        "\n",
        "# --- 4. OLS Regression for Shannon Diversity ---\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "print(\"OLS Regression Results for Shannon Diversity:\")\n",
        "model_shannon = sm.OLS(diversity_df['shannon'], X_sm)\n",
        "results_shannon = model_shannon.fit()\n",
        "print(results_shannon.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8608d03"
      },
      "source": [
        "Summarize the data quality and statistical significance of environmental predictors based on previous analysis.\n",
        "\n",
        "The analysis confirmed that there are **0** missing values in both the species abundance data (`dune`) and the environmental data (`dune_env`).\n",
        "\n",
        "For Species Richness, no individual predictors were statistically significant ($p > 0.05$). For Shannon Diversity, the predictor related to the specific \"Manure\" category level (variable `x4_3`) was significant with a p-value of **0.015**.\n",
        "\n",
        "Data Analysis Key Findings\n",
        "\n",
        "Data Quality: Both the `dune` and `dune_env` DataFrames are complete, with **0** null values found across all columns, ensuring the data was clean for regression analysis.\n",
        "Species Richness Model: The OLS regression for richness achieved an $R^2$ of **0.739** (Adjusted $R^2$: 0.292). However, despite the high explained variance, none of the environmental features showed individual statistical significance.\n",
        "Shannon Diversity Model: The model for Shannon diversity yielded an $R^2$ of **0.700** (Adjusted $R^2$: 0.187). The predictor corresponding to the 3rd level of the 'Manure' category (`x4_3`) was the only significant variable ($p = 0.015$).\n",
        "Multicollinearity: Both models reported an extremely large condition number ($\\approx 1.29 \\times 10^{16}$), indicating severe multicollinearity among the environmental predictors (likely due to One-Hot Encoding and potential correlations between variables like 'Management' and 'Use').\n",
        "\n",
        "Insights or Next Steps:\n",
        "Address Multicollinearity: The extreme condition numbers and the gap between $R^2$ and Adjusted $R^2$ suggest the models are overfitted and predictors are redundant. Reducing dimensionality (e.g., via PCA) or performing feature selection (e.g., Variance Inflation Factor analysis) is necessary to isolate the true drivers of diversity.\n",
        "Model Interpretation: While the environmental variables collectively explain nearly **70-74%** of the variance in diversity, the specific influence of individual factors is currently masked by their high correlation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fe6eee3"
      },
      "source": [
        "Perform 5-fold cross-validation using the existing OLS pipeline to calculate the Mean Test R² for both 'richness' and 'shannon' targets. Then, extract the AIC and BIC values from the previously generated `statsmodels` results (`results_richness` and `results_shannon`) and create a summary DataFrame that compares the cross-validation scores with the AIC/BIC model selection criteria."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34b9304f"
      },
      "source": [
        "Cross-Validation and Model Assessment\n",
        "\n",
        "Perform 5-fold cross-validation for both richness and Shannon diversity using the existing OLS pipeline to assess generalization, and compare these results with the AIC and BIC metrics obtained from the statsmodels analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b725e98"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import rpy2.robjects as ro\n",
        "from rpy2.robjects.packages import importr\n",
        "from rpy2.robjects import pandas2ri\n",
        "\n",
        "# --- 1. Load Data (if missing) ---\n",
        "if 'dune_env' not in locals() or 'dune' not in locals():\n",
        "    print(\"Loading dune data via rpy2...\")\n",
        "    utils = importr('utils')\n",
        "    try:\n",
        "        utils.install_packages('vegan', repos='https://cloud.r-project.org')\n",
        "    except:\n",
        "        pass\n",
        "    ro.r('library(vegan)')\n",
        "    ro.r('data(\"dune\")')\n",
        "    ro.r('data(\"dune.env\")')\n",
        "    pandas2ri.activate()\n",
        "    dune = pandas2ri.rpy2py(ro.r['dune'])\n",
        "    dune_env = pandas2ri.rpy2py(ro.r['dune.env'])\n",
        "\n",
        "# --- 2. Calculate Diversity Metrics (if missing) ---\n",
        "if 'div_metrics' not in locals():\n",
        "    richness = (dune > 0).sum(axis=1)\n",
        "    abundance = dune.astype(float)\n",
        "    total_abundance = abundance.sum(axis=1)\n",
        "    p = abundance.div(total_abundance, axis=0)\n",
        "    shannon = -(p * np.log(p.replace(0, 1))).sum(axis=1)\n",
        "    div_metrics = pd.DataFrame({'richness': richness, 'shannon': shannon}, index=dune.index)\n",
        "\n",
        "# --- 3. Re-fit Statsmodels OLS (if results missing) ---\n",
        "# Using drop='first' here for statistical interpretation (AIC/BIC)\n",
        "if 'results_richness' not in locals() or 'results_shannon' not in locals():\n",
        "    print(\"Re-fitting statsmodels OLS for AIC/BIC...\")\n",
        "    numeric_features = [\"A1\"]\n",
        "    categorical_features = [\"Moisture\", \"Management\", \"Use\", \"Manure\"]\n",
        "\n",
        "    preprocessor_sm = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", StandardScaler(), numeric_features),\n",
        "            (\"cat\", OneHotEncoder(drop=\"first\", sparse_output=False), categorical_features),\n",
        "        ]\n",
        "    )\n",
        "    X_transformed = preprocessor_sm.fit_transform(dune_env)\n",
        "    X_sm = sm.add_constant(X_transformed)\n",
        "\n",
        "    results_richness = sm.OLS(div_metrics['richness'], X_sm).fit()\n",
        "    results_shannon = sm.OLS(div_metrics['shannon'], X_sm).fit()\n",
        "\n",
        "# --- 4. Define Sklearn Pipeline for CV ---\n",
        "# We use handle_unknown='ignore' and remove drop='first' to handle rare categories during CV splits\n",
        "preprocess_cv = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), [\"A1\"]),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown='ignore', sparse_output=False), [\"Moisture\", \"Management\", \"Use\", \"Manure\"]),\n",
        "    ]\n",
        ")\n",
        "ols_pipeline_cv = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocess_cv),\n",
        "        (\"reg\", LinearRegression()) # LinearRegression handles collinearity from no-drop encoding fine\n",
        "    ]\n",
        ")\n",
        "\n",
        "# --- 5. Perform Cross-Validation ---\n",
        "X_env = dune_env.copy()\n",
        "\n",
        "# CV for Richness\n",
        "cv_scores_richness = cross_val_score(\n",
        "    ols_pipeline_cv,\n",
        "    X_env,\n",
        "    div_metrics['richness'],\n",
        "    cv=5,\n",
        "    scoring='r2'\n",
        ")\n",
        "mean_cv_r2_richness = cv_scores_richness.mean()\n",
        "\n",
        "# CV for Shannon Diversity\n",
        "cv_scores_shannon = cross_val_score(\n",
        "    ols_pipeline_cv,\n",
        "    X_env,\n",
        "    div_metrics['shannon'],\n",
        "    cv=5,\n",
        "    scoring='r2'\n",
        ")\n",
        "mean_cv_r2_shannon = cv_scores_shannon.mean()\n",
        "\n",
        "# --- 6. Summarize Findings ---\n",
        "aic_richness = results_richness.aic\n",
        "bic_richness = results_richness.bic\n",
        "aic_shannon = results_shannon.aic\n",
        "bic_shannon = results_shannon.bic\n",
        "\n",
        "assessment_summary = pd.DataFrame({\n",
        "    'Mean CV R2': [mean_cv_r2_richness, mean_cv_r2_shannon],\n",
        "    'AIC': [aic_richness, aic_shannon],\n",
        "    'BIC': [bic_richness, bic_shannon]\n",
        "}, index=['Richness', 'Shannon'])\n",
        "\n",
        "print(\"Model Assessment Summary:\")\n",
        "display(assessment_summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed480217"
      },
      "source": [
        "Summarize the cross-validation findings alongside the AIC/BIC model selection criteria:\n",
        "\n",
        "The models demonstrate extremely poor generalization despite the calculated AIC/BIC values.\n",
        "Both models yielded highly negative Mean CV $R^2$ scores (**-19.11** for Richness and **-48.66** for Shannon), indicating that the OLS models perform significantly worse than a simple horizontal mean predictor on unseen data.\n",
        "AIC/BIC Context: While the Shannon model had significantly lower AIC/BIC values ($5.34$ / $18.29$) compared to Richness ($90.09$ / $103.03$)—suggesting a better fit relative to the information loss—the cross-validation results confirm that neither model is robust enough for prediction due to severe overfitting.\n",
        "\n",
        "Data Analysis Key Findings\n",
        "\n",
        "Cross-Validation Performance:\n",
        "    *   The **Richness** model resulted in a Mean CV $R^2$ of **-19.108**.\n",
        "    *   The **Shannon** diversity model resulted in a Mean CV $R^2$ of **-48.664**.\n",
        "    *   These deeply negative scores were caused by the small dataset size ($n=20$) combined with the high dimensionality introduced by One-Hot Encoding categorical variables (\"Moisture\", \"Management\", \"Use\", \"Manure\").\n",
        "\n",
        "Model Selection Criteria (In-Sample Fit):\n",
        "Richness: AIC of **90.09** and BIC of **103.03**.\n",
        "Shannon: AIC of **5.34** and BIC of **18.29**.\n",
        "The large discrepancy between the AIC/BIC values for the two targets is due to the scale and variance of the target variables themselves, but the consistent failure in cross-validation highlights that low AIC/BIC in this context does not guarantee predictive power on small datasets.\n",
        "\n",
        "Insights or Next Steps\n",
        "\n",
        "Severe Overfitting: The negative $R^2$ values confirm that the OLS model is too complex for the limited number of observations (20 samples). The model is memorizing the training noise rather than learning underlying patterns.\n",
        "Recommendation: Future modeling should prioritize dimensionality reduction (e.g., selecting only the most critical features) or utilizing regularized regression methods (such as Ridge or Lasso) to constrain model coefficients and improve generalization.\n"
      ]
    }
  ]
}