{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqA9wHHSYPRY6lmGRv4utS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alfredqbit/NU-DDS-8515/blob/main/sepulvedaADDS-8515-4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTwjtRRcn8Fl"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# # Factor Analysis and Logistic Regression on the Consumer Behavior Dataset\n",
        "#\n",
        "# This notebook applies Factor Analysis (FA) to the Consumer Behavior dataset. We perform preprocessing,\n",
        "# factor extraction and rotation, and evaluate how FA impacts machine learning model performance.\n",
        "\n",
        "# %% [python]\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.decomposition import FactorAnalysis\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create figures directory\n",
        "FIG_DIR = \"figures\"\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## Step 1: Dataset Selection, Loading, and Exploratory Data Analysis (EDA)\n",
        "\n",
        "# %%\n",
        "# Create synthetic data for illustration purposes\n",
        "np.random.seed(42)\n",
        "n_samples = 200\n",
        "n_features = 10\n",
        "X = np.random.randn(n_samples, n_features)\n",
        "y = np.random.randint(0, 2, n_samples)  # Binary classification\n",
        "\n",
        "# Create DataFrame\n",
        "feature_names = [f'Feature_{i+1}' for i in range(n_features)]\n",
        "df = pd.DataFrame(X, columns=feature_names)\n",
        "df['target'] = y\n",
        "\n",
        "# Show basic information\n",
        "df.head(), df.describe(), df.isnull().sum(), df['target'].value_counts()\n",
        "\n",
        "# %% [markdown]\n",
        "# ## Step 2: Data Preprocessing and Feature Engineering\n",
        "\n",
        "# %%\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(df.drop(columns='target'))\n",
        "\n",
        "# Check standardized data\n",
        "pd.DataFrame(X_scaled, columns=feature_names).head()\n",
        "\n",
        "# %% [markdown]\n",
        "# ## Step 3: Conduct Factor Analysis\n",
        "\n",
        "# %%\n",
        "# Check correlation matrix\n",
        "correlation_matrix = np.corrcoef(X_scaled.T)\n",
        "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm')\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.savefig(os.path.join(FIG_DIR, 'correlation_matrix.png'))\n",
        "plt.show()\n",
        "\n",
        "# Perform Factor Analysis\n",
        "fa = FactorAnalysis(n_components=3)\n",
        "fa.fit(X_scaled)\n",
        "\n",
        "# Factor loadings\n",
        "loadings_df = pd.DataFrame(fa.components_, columns=feature_names)\n",
        "loadings_df\n",
        "\n",
        "# Plot the factor loadings\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(loadings_df, annot=True, cmap='coolwarm')\n",
        "plt.title('Factor Loadings for FA Components')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(FIG_DIR, 'factor_loadings.png'))\n",
        "plt.show()\n",
        "\n",
        "# %% [markdown]\n",
        "# ## Step 4: Data Visualization and Interpretation\n",
        "\n",
        "# %% [markdown]\n",
        "# ## Step 5: Machine Learning Model on Original Features\n",
        "\n",
        "# %%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression pipeline on original features\n",
        "baseline_pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", LogisticRegression(max_iter=1000, multi_class=\"auto\"))\n",
        "])\n",
        "\n",
        "t0 = time.time()\n",
        "baseline_pipeline.fit(X_train, y_train)\n",
        "t1 = time.time()\n",
        "\n",
        "y_pred_baseline = baseline_pipeline.predict(X_test)\n",
        "\n",
        "print(f\"Baseline model accuracy: {accuracy_score(y_test, y_pred_baseline)}\")\n",
        "print(\"Classification report:\")\n",
        "print(classification_report(y_test, y_pred_baseline))\n",
        "print(f\"Training time (s): {t1 - t0}\")\n",
        "\n",
        "# %% [markdown]\n",
        "# ## Step 6: Apply Factor Analysis to Transform Data\n",
        "\n",
        "# %%\n",
        "X_fa = fa.transform(X_scaled)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## Step 7: Train Model on FA-transformed Data\n",
        "\n",
        "# %%\n",
        "# Logistic Regression pipeline on FA-transformed features\n",
        "pca_pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"fa\", FactorAnalysis(n_components=3)),  # Same number of components\n",
        "    (\"clf\", LogisticRegression(max_iter=1000, multi_class=\"auto\"))\n",
        "])\n",
        "\n",
        "t0 = time.time()\n",
        "pca_pipeline.fit(X_train, y_train)\n",
        "t1 = time.time()\n",
        "\n",
        "y_pred_fa = pca_pipeline.predict(X_test)\n",
        "\n",
        "print(f\"FA-transformed model accuracy: {accuracy_score(y_test, y_pred_fa)}\")\n",
        "print(\"Classification report:\")\n",
        "print(classification_report(y_test, y_pred_fa))\n",
        "print(f\"Training time (s): {t1 - t0}\")\n",
        "\n",
        "# %% [markdown]\n",
        "# ## Step 8: Compare Performance Before and After FA\n",
        "\n",
        "# %%\n",
        "# Accuracy comparison\n",
        "results = pd.DataFrame({\n",
        "    \"Model\": [\"Baseline (Original Features)\", \"FA-transformed Features\"],\n",
        "    \"Accuracy\": [accuracy_score(y_test, y_pred_baseline), accuracy_score(y_test, y_pred_fa)],\n",
        "})\n",
        "\n",
        "# Save the results as PNG and CSV\n",
        "results.to_csv(os.path.join(FIG_DIR, 'results_table.csv'), index=False)\n",
        "\n",
        "# Bar chart comparison\n",
        "plt.figure()\n",
        "plt.bar(results[\"Model\"], results[\"Accuracy\"])\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Model Accuracy Comparison: Original vs FA-Transformed Features\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(FIG_DIR, 'accuracy_comparison.png'))\n",
        "plt.show()"
      ]
    }
  ]
}