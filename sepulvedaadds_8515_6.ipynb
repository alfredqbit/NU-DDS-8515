{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V6E1",
      "authorship_tag": "ABX9TyMuESMg0Yn2y1v13nUnHrVa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alfredqbit/NU-DDS-8515/blob/main/sepulvedaadds_8515_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment 6: ANOVA and MANOVA on A Marketing Dataset\n",
        "\n",
        "Dataset: `digital_marketing_campaign_dataset.csv`\n",
        "Source: Kaggle / Opendatabay (Digital Marketing Conversion Dataset)\n",
        "\n",
        "Goals:\n",
        " - One-way ANOVA: PreviousPurchases ~ CampaignChannel\n",
        " - Two-way ANOVA: ClickThroughRate ~ CampaignType * IncomeSegment\n",
        " - MANOVA: (ClickThroughRate, TimeOnSite) ~ CampaignChannel"
      ],
      "metadata": {
        "id": "SRwrD8tVcBqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.multivariate.manova import MANOVA\n",
        "from statsmodels.graphics.factorplots import interaction_plot\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "FIG_DIR = \"figures\"\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "E4pPR_8gcPuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44ff0e96"
      },
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    import statsmodels\n",
        "except ImportError:\n",
        "    print(\"statsmodels not found, installing...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"statsmodels\"])\n",
        "    print(\"statsmodels installed.\")\n",
        "    import statsmodels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e65699ca"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset from the sample_data directory\n",
        "def load_ad_dataset() -> pd.DataFrame:\n",
        "  file_path = 'sample_data/Dataset_Ads.csv'\n",
        "  print(f\"Loading dataset from {file_path}...\")\n",
        "\n",
        "  try:\n",
        "      df_ads = pd.read_csv(file_path)\n",
        "      print(\"Dataset loaded successfully.\")\n",
        "      display(df_ads.head())\n",
        "      display(df_ads.decribe())\n",
        "      display(df_ads.info())\n",
        "      return df_ads\n",
        "  except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {file_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Data loading and preprocessing pipeline"
      ],
      "metadata": {
        "id": "i325YbzpcVI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_raw_digital_marketing_dataset(\n",
        "    source: str = \"auto\",\n",
        "    local_path: str | None = None,\n",
        "    download_dir: str = \"data\"\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load `digital_marketing_campaign_dataset.csv` from:\n",
        "      - a local file,\n",
        "      - the Kaggle dataset\n",
        "        `rabieelkharoua/predict-conversion-in-digital-marketing-dataset`,\n",
        "      - or (optionally) a public raw URL.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    source : {'auto', 'local', 'kaggle', 'github'}\n",
        "        'auto'  : try local_path, then Kaggle path (if on Kaggle),\n",
        "                  then GitHub raw mirror.\n",
        "        'local' : require local_path to be a valid file.\n",
        "        'kaggle': use Kaggle CLI/API to download.\n",
        "        'github': load from a public raw URL mirror of the same CSV.\n",
        "    local_path : str or None\n",
        "        Path to a local CSV file, if available.\n",
        "    download_dir : str\n",
        "        Directory where Kaggle downloads / extracted files are stored.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    df : pandas.DataFrame\n",
        "    \"\"\"\n",
        "    filename = \"digital_marketing_campaign_dataset.csv\"\n",
        "\n",
        "    # --- 1. AUTO mode: try local, then Kaggle input path, then GitHub raw ---\n",
        "    if source == \"auto\":\n",
        "        # (a) explicit local path\n",
        "        if local_path is not None and os.path.exists(local_path):\n",
        "            print(f\"Loading dataset from local path: {local_path}\")\n",
        "            return pd.read_csv(local_path)\n",
        "\n",
        "        # (b) Kaggle built-in path (when running inside Kaggle notebooks)\n",
        "        kaggle_input = \"/kaggle/input/predict-conversion-in-digital-marketing-dataset/digital_marketing_campaign_dataset.csv\"\n",
        "        if os.path.exists(kaggle_input):\n",
        "            print(f\"Loading dataset from Kaggle input path: {kaggle_input}\")\n",
        "            return pd.read_csv(kaggle_input)\n",
        "\n",
        "        # (c) GitHub raw mirror as a last resort (same CSV mirrored on GitHub)\n",
        "        github_raw_url = (\n",
        "            \"https://raw.githubusercontent.com/\"\n",
        "            \"Elakkiya-U/Digital-marketing-campaign/\"\n",
        "            \"main/Digital_Marketing_Campaign_Dataset.csv\"\n",
        "        )\n",
        "        print(f\"Loading dataset from GitHub raw URL: {github_raw_url}\")\n",
        "        return pd.read_csv(github_raw_url)\n",
        "\n",
        "    # --- 2. LOCAL mode (explicit) ---\n",
        "    if source == \"local\":\n",
        "        if local_path is None:\n",
        "            raise ValueError(\"source='local' requires a valid local_path.\")\n",
        "        if not os.path.exists(local_path):\n",
        "            raise FileNotFoundError(f\"Local file not found: {local_path}\")\n",
        "        print(f\"Loading dataset from local file: {local_path}\")\n",
        "        return pd.read_csv(local_path)\n",
        "\n",
        "    # --- 3. KAGGLE mode (non-Kaggle environment, using Kaggle API) ---\n",
        "    if source == \"kaggle\":\n",
        "        # You must have:\n",
        "        #   pip install kaggle\n",
        "        #   KAGGLE_USERNAME and KAGGLE_KEY set in your environment,\n",
        "        #   or kaggle.json configured in ~/.kaggle/\n",
        "        try:\n",
        "            from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "        except ImportError as e:\n",
        "            raise ImportError(\n",
        "                \"Kaggle API not installed. Run `pip install kaggle` first.\"\n",
        "            ) from e\n",
        "\n",
        "        os.makedirs(download_dir, exist_ok=True)\n",
        "\n",
        "        dataset_slug = \"rabieelkharoua/predict-conversion-in-digital-marketing-dataset\"\n",
        "        print(f\"Downloading '{filename}' from Kaggle dataset: {dataset_slug}\")\n",
        "\n",
        "        api = KaggleApi()\n",
        "        api.authenticate()\n",
        "\n",
        "        api.dataset_download_file(\n",
        "            dataset_slug,\n",
        "            file_name=filename,\n",
        "            path=download_dir,\n",
        "            force=True\n",
        "        )\n",
        "\n",
        "        zip_path = os.path.join(download_dir, filename + \".zip\")\n",
        "        if os.path.exists(zip_path):\n",
        "            print(f\"Extracting {zip_path} ...\")\n",
        "            with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
        "                zf.extractall(download_dir)\n",
        "        csv_path = os.path.join(download_dir, filename)\n",
        "        if not os.path.exists(csv_path):\n",
        "            raise FileNotFoundError(f\"Could not find extracted CSV at {csv_path}\")\n",
        "        print(f\"Loading dataset from extracted CSV: {csv_path}\")\n",
        "        return pd.read_csv(csv_path)\n",
        "\n",
        "    # --- 4. GitHub mode (explicit raw HTTP) ---\n",
        "    if source == \"github\":\n",
        "        github_raw_url = (\n",
        "            \"https://raw.githubusercontent.com/\"\n",
        "            \"Elakkiya-U/Digital-marketing-campaign/\"\n",
        "            \"main/Digital_Marketing_Campaign_Dataset.csv\"\n",
        "        )\n",
        "        print(f\"Loading dataset from GitHub raw URL: {github_raw_url}\")\n",
        "        return pd.read_csv(github_raw_url)\n",
        "\n",
        "    # If we got here, source was invalid.\n",
        "    raise ValueError(f\"Unknown source '{source}'. Use 'auto', 'local', 'kaggle', or 'github'.\")\n",
        "\n",
        "# Example call (will be used later):\n",
        "# df = load_and_prepare_data(\"digital_marketing_campaign_dataset.csv\")"
      ],
      "metadata": {
        "id": "NNqGhFuocdNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One-way ANOVA pipeline: PreviousPurchases ~ CampaignChannel\n",
        "\n",
        "We create three income-based segments (Low, Medium, High)\n",
        "via tertiles, to use as a factor in the two-way ANOVA."
      ],
      "metadata": {
        "id": "jdfIf54hcjB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_oneway_anova_purchases(df: pd.DataFrame, fig_dir: str = FIG_DIR):\n",
        "    \"\"\"\n",
        "    Run one-way ANOVA: PreviousPurchases ~ CampaignChannel,\n",
        "    check assumptions, and export diagnostic plots.\n",
        "    \"\"\"\n",
        "    if \"PreviousPurchases\" not in df.columns or \"CampaignChannel\" not in df.columns:\n",
        "        raise ValueError(\"Required columns 'PreviousPurchases' or 'CampaignChannel' missing.\")\n",
        "\n",
        "    # Drop rows with missing values relevant to this analysis\n",
        "    df_1way = df.dropna(subset=[\"PreviousPurchases\", \"CampaignChannel\"])\n",
        "\n",
        "    # Fit ANOVA model\n",
        "    model = ols(\"PreviousPurchases ~ C(CampaignChannel)\", data=df_1way).fit()\n",
        "    anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "    print(\"One-way ANOVA: PreviousPurchases ~ CampaignChannel\")\n",
        "    display(anova_table)\n",
        "\n",
        "    resid = model.resid\n",
        "    fitted = model.fittedvalues\n",
        "\n",
        "    # Levene's test for homogeneity of variance\n",
        "    groups = [g[\"PreviousPurchases\"].values for _, g in df_1way.groupby(\"CampaignChannel\")]\n",
        "    lev_stat, lev_p = stats.levene(*groups)\n",
        "    print(f\"\\nLevene's test: stat={lev_stat:.3f}, p={lev_p:.3f}\")\n",
        "\n",
        "    # Shapiro-Wilk for normality of residuals, with sampling for large N\n",
        "    sample_size_limit = 5000\n",
        "    if len(resid) > sample_size_limit:\n",
        "        sampled_resid = resid.sample(n=sample_size_limit, random_state=42)\n",
        "        print(f\"Shapiro-Wilk (residuals, sampled N={sample_size_limit}):\")\n",
        "        sh_stat, sh_p = stats.shapiro(sampled_resid)\n",
        "    else:\n",
        "        print(f\"Shapiro-Wilk (residuals): \")\n",
        "        sh_stat, sh_p = stats.shapiro(resid)\n",
        "    print(f\"  stat={sh_stat:.3f}, p={sh_p:.3f}\")\n",
        "\n",
        "    # Q-Q plot for residuals\n",
        "    sm.qqplot(resid, line=\"45\")\n",
        "    plt.title(\"One-way ANOVA Residuals Q-Q Plot\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(fig_dir, \"oneway_resid_qq.png\"), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # Residuals vs fitted\n",
        "    plt.figure()\n",
        "    plt.scatter(fitted, resid, alpha=0.6)\n",
        "    plt.axhline(0, color=\"gray\", linewidth=0.8)\n",
        "    plt.xlabel(\"Fitted values\")\n",
        "    plt.ylabel(\"Residuals\")\n",
        "    plt.title(\"One-way ANOVA: Residuals vs Fitted\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(fig_dir, \"oneway_resid_vs_fitted.png\"), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # Boxplot of PreviousPurchases by CampaignChannel\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.boxplot(x=\"CampaignChannel\", y=\"PreviousPurchases\", data=df_1way)\n",
        "    plt.title(\"Previous Purchases by Campaign Channel\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(fig_dir, \"box_purchases_by_channel.png\"), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    return model, anova_table"
      ],
      "metadata": {
        "id": "cTLMj7nicrQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Two-way ANOVA pipeline: ClickThroughRate ~ CampaignType * IncomeSegment"
      ],
      "metadata": {
        "id": "DZkHukVFcxf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_twoway_anova_ctr(df: pd.DataFrame, fig_dir: str = FIG_DIR):\n",
        "    \"\"\"\n",
        "    Run two-way ANOVA:\n",
        "      ClickThroughRate ~ CampaignType * IncomeSegment\n",
        "    Check assumptions and export interaction and diagnostic plots.\n",
        "    \"\"\"\n",
        "    required = [\"ClickThroughRate\", \"CampaignType\", \"IncomeSegment\"]\n",
        "    missing = [c for c in required if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns for two-way ANOVA: {missing}\")\n",
        "\n",
        "    df_2way = df.dropna(subset=required)\n",
        "\n",
        "    # Fit two-way ANOVA model with interaction\n",
        "    formula = \"ClickThroughRate ~ C(CampaignType) * C(IncomeSegment)\"\n",
        "    model = ols(formula, data=df_2way).fit()\n",
        "    anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "    print(\"Two-way ANOVA: ClickThroughRate ~ CampaignType * IncomeSegment\")\n",
        "    display(anova_table)\n",
        "\n",
        "    resid = model.resid\n",
        "\n",
        "    # Shapiro-Wilk test for residuals, with sampling for large N\n",
        "    sample_size_limit = 5000\n",
        "    if len(resid) > sample_size_limit:\n",
        "        sampled_resid = resid.sample(n=sample_size_limit, random_state=42)\n",
        "        print(f\"\\nShapiro-Wilk (two-way residuals, sampled N={sample_size_limit}):\")\n",
        "        sh_stat, sh_p = stats.shapiro(sampled_resid)\n",
        "    else:\n",
        "        print(f\"\\nShapiro-Wilk (two-way residuals):\")\n",
        "        sh_stat, sh_p = stats.shapiro(resid)\n",
        "    print(f\"  stat={sh_stat:.3f}, p={sh_p:.3f}\")\n",
        "\n",
        "    # Levene's test across CampaignType x IncomeSegment cells (add observed=False)\n",
        "    cells = [g[\"ClickThroughRate\"].values\n",
        "             for _, g in df_2way.groupby([\"CampaignType\", \"IncomeSegment\"], observed=False)]\n",
        "    lev_stat, lev_p = stats.levene(*cells)\n",
        "    print(f\"Levene's test (two-way): stat={lev_stat:.3f}, p={lev_p:.3f}\")\n",
        "\n",
        "    # Interaction plot\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    interaction_plot(\n",
        "        df_2way[\"CampaignType\"],\n",
        "        df_2way[\"IncomeSegment\"],\n",
        "        df_2way[\"ClickThroughRate\"],\n",
        "        markers=[\"o\", \"s\", \"D\"],\n",
        "        ms=6\n",
        "    )\n",
        "    plt.ylabel(\"Mean ClickThroughRate\")\n",
        "    plt.title(\"Interaction: CampaignType x IncomeSegment on CTR\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(fig_dir, \"interaction_ctr_adtype_segment.png\"), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # Q-Q plot for residuals\n",
        "    sm.qqplot(resid, line=\"45\")\n",
        "    plt.title(\"Two-way ANOVA Residuals Q-Q Plot (CTR)\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(fig_dir, \"twoway_ctr_qqplot.png\"), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # Residuals vs fitted\n",
        "    plt.figure()\n",
        "    plt.scatter(model.fittedvalues, resid, alpha=0.5)\n",
        "    plt.axhline(0, color=\"gray\", linewidth=0.8)\n",
        "    plt.xlabel(\"Fitted values\")\n",
        "    plt.ylabel(\"Residuals\")\n",
        "    plt.title(\"Two-way ANOVA: CTR Residuals vs Fitted\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(fig_dir, \"twoway_ctr_resid_fitted.png\"), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    return model, anova_table"
      ],
      "metadata": {
        "id": "hn7WF7vcc1pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MANOVA pipeline: model: (ClickThroughRate, TimeOnSite) ~ CampaignChannel\n",
        "\n",
        "Includes:\n",
        " - MANOVA via statsmodels\n",
        " - Assumption checks (Shapiro, Box's M)\n",
        " - Canonical discriminant visualization via sklearn Pipeline (StandardScaler + LDA)\n",
        "\n",
        "Conditionally execute univariate ANOVAs and diagnostics when the MANOVA result (Wilks' lambda) is significant (p < 0.05).\n",
        "\n"
      ],
      "metadata": {
        "id": "5dD2Znqmc8Vf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c6c4d04"
      },
      "source": [
        "from numpy.linalg import det, inv\n",
        "from scipy.stats import chi2\n",
        "\n",
        "def box_m_test(df_y: pd.DataFrame, group_labels: np.ndarray):\n",
        "    \"\"\"\n",
        "    Box's M test for equality of covariance matrices across groups.\n",
        "    \"\"\"\n",
        "    y = df_y.values\n",
        "    groups = np.unique(group_labels)\n",
        "    p = y.shape[1]\n",
        "    N = y.shape[0]\n",
        "\n",
        "    covs = []\n",
        "    ns = []\n",
        "    for g in groups:\n",
        "        Yg = y[group_labels == g]\n",
        "        ns.append(Yg.shape[0])\n",
        "        covs.append(np.cov(Yg, rowvar=False))\n",
        "\n",
        "    ns = np.array(ns)\n",
        "    covs = np.array(covs)\n",
        "\n",
        "    # Pooled covariance\n",
        "    Sp = sum((ns[i] - 1) * covs[i] for i in range(len(groups))) / (N - len(groups))\n",
        "\n",
        "    M = (N - len(groups)) * np.log(det(Sp)) - sum(\n",
        "        (ns[i] - 1) * np.log(det(covs[i])) for i in range(len(groups))\n",
        "    )\n",
        "\n",
        "    # Correction factor\n",
        "    C = ((2 * p**2 + 3 * p - 1) /\n",
        "         (6 * (p + 1) * (len(groups) - 1))) * \\\n",
        "        (sum(1 / (ns[i] - 1) for i in range(len(groups))) -\n",
        "         1 / (N - len(groups)))\n",
        "\n",
        "    chi2_approx = M * (1 - C)\n",
        "    df_val = (len(groups) - 1) * p * (p + 1) / 2\n",
        "    p_value = 1 - chi2.cdf(chi2_approx, df_val)\n",
        "\n",
        "    return M, chi2_approx, df_val, p_value\n",
        "\n",
        "\n",
        "def run_manova_and_canonical(df: pd.DataFrame, fig_dir: str = FIG_DIR):\n",
        "    \"\"\"\n",
        "    Run MANOVA:\n",
        "      (ClickThroughRate, TimeOnSite) ~ CampaignChannel\n",
        "    + assumption checks\n",
        "    + conditional univariate ANOVAs (if MANOVA significant)\n",
        "    + canonical discriminant visualization via sklearn Pipeline (StandardScaler + LDA).\n",
        "    \"\"\"\n",
        "    required = [\"ClickThroughRate\", \"TimeOnSite\", \"CampaignChannel\"]\n",
        "    missing = [c for c in required if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns for MANOVA: {missing}\")\n",
        "\n",
        "    df_manova = df.dropna(subset=required)\n",
        "\n",
        "    # MANOVA using statsmodels\n",
        "    formula = \"ClickThroughRate + TimeOnSite ~ C(CampaignChannel)\"\n",
        "    manova = MANOVA.from_formula(formula, data=df_manova)\n",
        "\n",
        "    # Capture MANOVA results\n",
        "    mv_results = manova.mv_test()\n",
        "    print(\"MANOVA results (CTR, TimeOnSite ~ CampaignChannel):\")\n",
        "    print(mv_results)\n",
        "\n",
        "    # Assumption checks: univariate Shapiro-Wilk for each DV, with sampling for large N\n",
        "    sample_size_limit = 5000\n",
        "    for dv in [\"ClickThroughRate\", \"TimeOnSite\"]:\n",
        "        data_for_shapiro = df_manova[dv]\n",
        "        if len(data_for_shapiro) > sample_size_limit:\n",
        "            sampled_data = data_for_shapiro.sample(n=sample_size_limit, random_state=42)\n",
        "            print(f\"\\nShapiro-Wilk for {dv}: (applied to a random sample of {sample_size_limit} due to large N)\")\n",
        "            stat, pval = stats.shapiro(sampled_data)\n",
        "        else:\n",
        "            print(f\"\\nShapiro-Wilk for {dv}:\")\n",
        "            stat, pval = stats.shapiro(data_for_shapiro)\n",
        "        print(f\"  stat={stat:.3f}, p={pval:.3f}\")\n",
        "\n",
        "    # Box's M test for equality of covariance matrices\n",
        "    Y = df_manova[[\"ClickThroughRate\", \"TimeOnSite\"]]\n",
        "    groups = df_manova[\"CampaignChannel\"].values\n",
        "    M, chi2_val, df_box, p_box = box_m_test(Y, groups)\n",
        "    print(f\"\\nBox's M test: M={M:.3f}, chi2={chi2_val:.3f}, df={df_box:.0f}, p={p_box:.3f}\")\n",
        "\n",
        "    # Check MANOVA significance (Wilks' lambda)\n",
        "    # The key in results is typically the term name 'C(CampaignChannel)'\n",
        "    term_name = 'C(CampaignChannel)'\n",
        "    if term_name in mv_results.results:\n",
        "        stats_df = mv_results.results[term_name]['stat']\n",
        "        # Extract Wilks' lambda p-value\n",
        "        # The row index is \"Wilks' lambda\" and column is \"Pr > F\"\n",
        "        wilks_p = stats_df.loc[\"Wilks' lambda\", \"Pr > F\"]\n",
        "        print(f\"\\nWilks' Lambda p-value: {wilks_p:.4g}\")\n",
        "\n",
        "        if wilks_p < 0.05:\n",
        "            print(\"MANOVA result is significant (p < 0.05). Proceeding to univariate ANOVAs.\")\n",
        "            # Follow-up univariate ANOVAs\n",
        "        else:\n",
        "            print(\"\\nMANOVA result is not significant (p >= 0.05).\")\n",
        "        for dv in [\"ClickThroughRate\", \"TimeOnSite\"]:\n",
        "            print(f\"\\nFollowup Univariate ANOVA: {dv} ~ CampaignChannel\")\n",
        "            model_dv = ols(f\"{dv} ~ C(CampaignChannel)\", data=df_manova).fit()\n",
        "            anova_dv = sm.stats.anova_lm(model_dv, typ=2)\n",
        "            display(anova_dv)\n",
        "    else:\n",
        "        print(f\"\\nWarning: Term '{term_name}' not found in MANOVA results. Cannot check significance automatically.\")\n",
        "\n",
        "    # Canonical discriminant scores via sklearn Pipeline: StandardScaler + LDA\n",
        "    lda_pipeline = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"lda\", LinearDiscriminantAnalysis(n_components=2))\n",
        "    ])\n",
        "\n",
        "    Y_numeric = Y.values\n",
        "    scores = lda_pipeline.fit_transform(Y_numeric, groups)\n",
        "\n",
        "    can_df = pd.DataFrame(scores, columns=[\"Can1\", \"Can2\"])\n",
        "    can_df[\"CampaignChannel\"] = groups\n",
        "\n",
        "    plt.figure(figsize=(7, 5))\n",
        "    sns.scatterplot(\n",
        "        x=\"Can1\", y=\"Can2\",\n",
        "        hue=\"CampaignChannel\",\n",
        "        data=can_df,\n",
        "        s=60, alpha=0.8\n",
        "    )\n",
        "    plt.axhline(0, color=\"gray\", linewidth=0.8)\n",
        "    plt.axvline(0, color=\"gray\", linewidth=0.8)\n",
        "    plt.title(\"Canonical Score Plot: CTR & TimeOnSite by CampaignChannel\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(fig_dir, \"manova_canonical_scatter.png\"), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    return manova, can_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the full analysis pipeline"
      ],
      "metadata": {
        "id": "mD9nSPfQdHvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = load_raw_digital_marketing_dataset()\n",
        "# df = load_ad_dataset()\n",
        "\n",
        "# Create IncomeSegment for two-way ANOVA\n",
        "df['IncomeSegment'] = pd.qcut(\n",
        "    df['Income'],\n",
        "    q=3,\n",
        "    labels=['Low', 'Medium', 'High'],\n",
        "    duplicates='drop'\n",
        ")\n",
        "\n",
        "print(\"Dataset preview:\")\n",
        "display(df.describe())\n",
        "display(df.head())\n",
        "display(df.info())\n",
        "\n",
        "print(\"\\nRunning one-way ANOVA pipeline...\")\n",
        "model_1way, anova_1way = run_oneway_anova_purchases(df)\n",
        "\n",
        "print(\"\\nRunning two-way ANOVA pipeline...\")\n",
        "model_2way, anova_2way = run_twoway_anova_ctr(df)\n",
        "\n",
        "print(\"\\nRunning MANOVA + canonical discriminant pipeline + followup AMOVA\")\n",
        "manova_res, canonical_scores_df = run_manova_and_canonical(df)\n",
        "\n",
        "print(\"\\nPipeline complete. Plots saved in the 'figures' subdirectory for downloading into full LaTeX report.\")"
      ],
      "metadata": {
        "id": "-14ZrqlJdLme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sanity check for modeling strategy:\n",
        "Generate synthetic dataset with moderate to mild significant effects and run full analysis pieline\n",
        "Check for consisten results"
      ],
      "metadata": {
        "id": "ayjdC-_o45PT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30c248cb"
      },
      "source": [
        "def generate_synthetic_marketing_data(n_samples=3000, seed=42):\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # 1. Generate Categorical Features\n",
        "    channels = ['Social Media', 'Email', 'PPC', 'Referral', 'SEO']\n",
        "    types = ['Awareness', 'Consideration', 'Conversion', 'Retention']\n",
        "    segments = ['Low', 'Medium', 'High']\n",
        "\n",
        "    data = {\n",
        "        'CampaignChannel': np.random.choice(channels, n_samples),\n",
        "        'CampaignType': np.random.choice(types, n_samples),\n",
        "        '_TrueSegment': np.random.choice(segments, n_samples) # Helper for income generation\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # 2. Generate Income based on Segment\n",
        "    def get_income(seg):\n",
        "        if seg == 'Low': return np.random.randint(20000, 45000)\n",
        "        if seg == 'Medium': return np.random.randint(45001, 80000)\n",
        "        return np.random.randint(80001, 150000)\n",
        "\n",
        "    df['Income'] = df['_TrueSegment'].apply(get_income)\n",
        "\n",
        "    # 3. Inject Effects for One-way ANOVA: PreviousPurchases ~ CampaignChannel\n",
        "    # Moderate: Max diff ~1.5, Sigma=2.5\n",
        "    pp_means = {'Social Media': 2.5, 'Email': 4.0, 'PPC': 2.8, 'Referral': 3.5, 'SEO': 3.0}\n",
        "    df['PreviousPurchases'] = df['CampaignChannel'].map(pp_means) + np.random.normal(0, 2.5, n_samples)\n",
        "    df['PreviousPurchases'] = df['PreviousPurchases'].clip(lower=0).astype(int)\n",
        "\n",
        "    # 4. Inject Effects for MANOVA: TimeOnSite ~ CampaignChannel\n",
        "    # Moderate: Max diff ~25, Sigma=20\n",
        "    tos_means = {'Social Media': 50.0, 'Email': 75.0, 'PPC': 45.0, 'Referral': 65.0, 'SEO': 55.0}\n",
        "    df['TimeOnSite'] = df['CampaignChannel'].map(tos_means) + np.random.normal(0, 20.0, n_samples)\n",
        "    df['TimeOnSite'] = df['TimeOnSite'].clip(lower=0)\n",
        "\n",
        "    # 5. Inject Effects for Two-way ANOVA & MANOVA:\n",
        "    # ClickThroughRate ~ CampaignType * IncomeSegment + CampaignChannel\n",
        "\n",
        "    base_ctr = 0.10\n",
        "\n",
        "    # Moderate Channel effects (for MANOVA)\n",
        "    channel_eff = {'Social Media': 0.00, 'Email': 0.03, 'PPC': 0.01, 'Referral': 0.02, 'SEO': 0.005}\n",
        "\n",
        "    # Moderate Type effects\n",
        "    type_eff = {'Awareness': 0.00, 'Consideration': 0.02, 'Conversion': 0.04, 'Retention': 0.01}\n",
        "\n",
        "    # Moderate Segment effects\n",
        "    seg_eff = {'Low': 0.00, 'Medium': 0.02, 'High': 0.03}\n",
        "\n",
        "    ctr_vec = base_ctr + \\\n",
        "              df['CampaignChannel'].map(channel_eff) + \\\n",
        "              df['CampaignType'].map(type_eff) + \\\n",
        "              df['_TrueSegment'].map(seg_eff)\n",
        "\n",
        "    # Moderate Interaction Effects\n",
        "    interaction_noise = np.random.normal(0, 0.04, n_samples)\n",
        "\n",
        "    def get_interaction(row):\n",
        "        if row['CampaignType'] == 'Conversion' and row['_TrueSegment'] == 'High':\n",
        "            return 0.04 # Moderate boost\n",
        "        if row['CampaignType'] == 'Awareness' and row['_TrueSegment'] == 'Low':\n",
        "            return -0.02 # Moderate penalty\n",
        "        return 0.0\n",
        "\n",
        "    df['ClickThroughRate'] = ctr_vec + df.apply(get_interaction, axis=1) + interaction_noise\n",
        "    df['ClickThroughRate'] = df['ClickThroughRate'].clip(0, 1)\n",
        "\n",
        "    # Cleanup\n",
        "    df.drop(columns=['_TrueSegment'], inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Generate the dataset\n",
        "print(\"Generating synthetic dataset with moderately significant effects (p ~< 0.5)...\")\n",
        "df_synthetic = generate_synthetic_marketing_data()\n",
        "\n",
        "# Preprocess\n",
        "df_synthetic['IncomeSegment'] = pd.qcut(\n",
        "    df_synthetic['Income'],\n",
        "    q=3,\n",
        "    labels=['Low', 'Medium', 'High'],\n",
        "    duplicates='drop'\n",
        ")\n",
        "\n",
        "print(\"Synthetic dataset preview:\")\n",
        "display(df_synthetic.head())\n",
        "\n",
        "# Run the Analysis Pipelines\n",
        "print(\"\\n--- 1. Running One-way ANOVA (PreviousPurchases ~ CampaignChannel) ---\")\n",
        "run_oneway_anova_purchases(df_synthetic)\n",
        "\n",
        "print(\"\\n--- 2. Running Two-way ANOVA (CTR ~ CampaignType * IncomeSegment) ---\")\n",
        "run_twoway_anova_ctr(df_synthetic)\n",
        "\n",
        "print(\"\\n--- 3. Running MANOVA ((CTR, TimeOnSite) ~ CampaignChannel) ---\")\n",
        "run_manova_and_canonical(df_synthetic)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}