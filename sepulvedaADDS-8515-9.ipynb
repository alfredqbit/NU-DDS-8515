{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyFTd8zkk5i8HxTnzCxJRN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alfredqbit/NU-DDS-8515/blob/main/sepulvedaADDS-8515-9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering and Discriminant Analysis on the WDBC Dataset\n",
        "#\n",
        "This notebook implements the analysis described in the paper:\n",
        " - Clustering: k-means, hierarchical clustering, DBSCAN\n",
        " - Discriminant analysis: LDA and QDA\n",
        " - Evaluation and visualization\n",
        "#\n",
        "All figures are saved into the `figures/` subdirectory for inclusion in LaTeX."
      ],
      "metadata": {
        "id": "Z5BLkAfwFO8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import AgglomerativeClustering, DBSCAN, KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.metrics import (\n",
        "    adjusted_rand_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    silhouette_score,\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Global plotting and output configuration\n",
        "\n",
        "FIG_DIR = Path(\"figures\")\n",
        "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (8, 6)\n",
        "plt.rcParams[\"font.size\"] = 12"
      ],
      "metadata": {
        "id": "xIAKbV9lFULK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Loading and Exploratory Analysis"
      ],
      "metadata": {
        "id": "MzW76fjWFdO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_wdbc(as_frame: bool = True):\n",
        "    \"\"\"\n",
        "    Load the Wisconsin Diagnostic Breast Cancer dataset.\n",
        "\n",
        "    Preference: ucimlrepo (direct from UCI). Fallback: scikit-learn.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "        bc = fetch_ucirepo(id=17)  # WDBC\n",
        "        X = bc.data.features.copy()\n",
        "        y = bc.data.targets.iloc[:, 0].copy()\n",
        "        # Map string labels to binary {0,1}\n",
        "        if y.dtype == object:\n",
        "            y = y.map({\"B\": 0, \"benign\": 0, \"M\": 1, \"malignant\": 1})\n",
        "        if not as_frame:\n",
        "            return X.values, y.values\n",
        "        return X, y\n",
        "    except Exception:\n",
        "        from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "        data = load_breast_cancer(as_frame=as_frame)\n",
        "        if as_frame:\n",
        "            X = data[\"data\"].copy()\n",
        "            y = pd.Series(data[\"target\"], name=\"diagnosis\")\n",
        "        else:\n",
        "            X, y = data[\"data\"], data[\"target\"]\n",
        "        return X, y\n",
        "\n",
        "\n",
        "# %%\n",
        "X, y = load_wdbc(as_frame=True)\n",
        "X.head()\n",
        "\n",
        "# %%\n",
        "print(\"Shape:\", X.shape)\n",
        "print(\"Target distribution:\")\n",
        "print(y.value_counts(normalize=True).rename(\"proportion\"))\n",
        "\n",
        "# %%\n",
        "# Basic correlation heatmap (for sanity)\n",
        "import seaborn as sns\n",
        "\n",
        "corr = X.corr()\n",
        "plt.figure()\n",
        "sns.heatmap(corr, cmap=\"coolwarm\", center=0, square=True, cbar_kws={\"shrink\": 0.7})\n",
        "plt.title(\"Feature Correlation Matrix (WDBC)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"wdbc_corr_heatmap.png\", dpi=300)\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "Rtv6t60pFgpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # 2. PCA Visualization"
      ],
      "metadata": {
        "id": "dtUTmEy3Fqcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=2, random_state=42)\n",
        "X_std = StandardScaler().fit_transform(X)\n",
        "X_pca = pca.fit_transform(X_std)\n",
        "\n",
        "df_pca = pd.DataFrame(X_pca, columns=[\"PC1\", \"PC2\"])\n",
        "df_pca[\"diagnosis\"] = y.values\n",
        "\n",
        "plt.figure()\n",
        "sns.scatterplot(\n",
        "    data=df_pca,\n",
        "    x=\"PC1\",\n",
        "    y=\"PC2\",\n",
        "    hue=\"diagnosis\",\n",
        "    palette=\"Set1\",\n",
        "    alpha=0.8,\n",
        ")\n",
        "plt.title(\"WDBC: First Two Principal Components by Diagnosis\")\n",
        "plt.legend(title=\"Diagnosis\", loc=\"best\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"wdbc_pca_true_labels.png\", dpi=300)\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "SjU0aWk0Fvtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Clustering Analysis\n",
        "#\n",
        "We standardize the features and then apply:\n",
        " - k-means for a range of K with elbow and silhouette analysis\n",
        " - agglomerative hierarchical clustering (Ward)\n",
        " - DBSCAN"
      ],
      "metadata": {
        "id": "TFA-l3gHFyOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_std = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "d5pm8n3vF6cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.1 k-Means: Elbow and Silhouette"
      ],
      "metadata": {
        "id": "iOSkAdc-F7ww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_kmeans_elbow_silhouette(X_std, y, k_range=range(2, 11)):\n",
        "    inertias = []\n",
        "    silhouettes = []\n",
        "    ari_scores = []\n",
        "\n",
        "    for k in k_range:\n",
        "        km = KMeans(n_clusters=k, n_init=20, random_state=42)\n",
        "        labels = km.fit_predict(X_std)\n",
        "        inertias.append(km.inertia_)\n",
        "        silhouettes.append(silhouette_score(X_std, labels))\n",
        "        ari_scores.append(adjusted_rand_score(y, labels))\n",
        "\n",
        "    return inertias, silhouettes, ari_scores\n",
        "\n",
        "\n",
        "k_range = range(2, 11)\n",
        "inertias, silhouettes, ari_scores = run_kmeans_elbow_silhouette(X_std, y, k_range)\n",
        "\n",
        "# Elbow plot\n",
        "plt.figure()\n",
        "plt.plot(list(k_range), inertias, marker=\"o\")\n",
        "plt.xlabel(\"Number of clusters K\")\n",
        "plt.ylabel(\"Inertia (within-cluster sum of squares)\")\n",
        "plt.title(\"k-Means Elbow Plot (WDBC)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"wdbc_kmeans_elbow.png\", dpi=300)\n",
        "plt.close()\n",
        "\n",
        "# Silhouette and ARI vs K\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(list(k_range), silhouettes, marker=\"o\", label=\"Silhouette\")\n",
        "ax.set_xlabel(\"Number of clusters K\")\n",
        "ax.set_ylabel(\"Silhouette score\")\n",
        "ax2 = ax.twinx()\n",
        "ax2.plot(list(k_range), ari_scores, marker=\"s\", color=\"tab:red\", label=\"ARI (vs. labels)\")\n",
        "ax2.set_ylabel(\"Adjusted Rand Index\")\n",
        "plt.title(\"k-Means Quality Metrics vs K\")\n",
        "fig.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"wdbc_kmeans_silhouette_ari.png\", dpi=300)\n",
        "plt.close()\n",
        "\n",
        "best_k = 2  # chosen based on elbow + interpretability\n"
      ],
      "metadata": {
        "id": "Zdshq0cHF-CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 3.2 k-Means: Cluster Visualization in PCA Space"
      ],
      "metadata": {
        "id": "3nyLcCDZGC3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "km_best = KMeans(n_clusters=best_k, n_init=20, random_state=42)\n",
        "cluster_labels = km_best.fit_predict(X_std)\n",
        "ari_best = adjusted_rand_score(y, cluster_labels)\n",
        "print(f\"k-means with K={best_k}, ARI vs labels: {ari_best:.3f}\")\n",
        "\n",
        "df_pca[\"cluster\"] = cluster_labels\n",
        "\n",
        "plt.figure()\n",
        "sns.scatterplot(\n",
        "    data=df_pca,\n",
        "    x=\"PC1\",\n",
        "    y=\"PC2\",\n",
        "    hue=\"cluster\",\n",
        "    palette=\"Set2\",\n",
        "    alpha=0.8,\n",
        ")\n",
        "plt.scatter(\n",
        "    pca.transform(km_best.cluster_centers_)[:, 0],\n",
        "    pca.transform(km_best.cluster_centers_)[:, 1],\n",
        "    marker=\"X\",\n",
        "    s=120,\n",
        "    edgecolor=\"black\",\n",
        "    label=\"Centroids\",\n",
        ")\n",
        "plt.title(f\"WDBC: PCA Projection with k-Means Clusters (K={best_k})\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"wdbc_kmeans_pca_clusters.png\", dpi=300)\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "ZO9t0dnoGFWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.3 Hierarchical Clustering (Ward)\n",
        "#\n",
        "For the dendrogram, we subsample points for readability."
      ],
      "metadata": {
        "id": "An2PPWb4GIrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "# Subsample for dendrogram (e.g., 120 points)\n",
        "rng = np.random.default_rng(42)\n",
        "idx_sub = rng.choice(len(X_std), size=min(120, len(X_std)), replace=False)\n",
        "Z = linkage(X_std[idx_sub], method=\"ward\", metric=\"euclidean\")\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "dendrogram(Z, truncate_mode=\"level\", p=5, no_labels=True)\n",
        "plt.title(\"Hierarchical Clustering Dendrogram (Ward, Subsample)\")\n",
        "plt.xlabel(\"Sample index\")\n",
        "plt.ylabel(\"Distance\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"wdbc_hierarchical_dendrogram.png\", dpi=300)\n",
        "plt.close()\n",
        "\n",
        "# Cut into two clusters and compute ARI\n",
        "agg = AgglomerativeClustering(n_clusters=2, linkage=\"ward\")\n",
        "hier_labels = agg.fit_predict(X_std)\n",
        "print(\"Agglomerative (Ward), ARI vs labels:\", adjusted_rand_score(y, hier_labels))"
      ],
      "metadata": {
        "id": "OhjegvbyGL69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.4 DBSCAN\n",
        "#\n",
        "We perform a quick sweep over eps values to see cluster structure."
      ],
      "metadata": {
        "id": "sGFiS9QyGPtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_dbscan_sweep(X_std, y, eps_values=(0.5, 0.7, 0.9), min_samples=5):\n",
        "    results = []\n",
        "    for eps in eps_values:\n",
        "        db = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "        labels = db.fit_predict(X_std)\n",
        "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "        n_noise = np.sum(labels == -1)\n",
        "        ari = adjusted_rand_score(y, labels) if n_clusters > 1 else np.nan\n",
        "        results.append((eps, n_clusters, n_noise, ari))\n",
        "    return pd.DataFrame(\n",
        "        results, columns=[\"eps\", \"n_clusters\", \"n_noise\", \"ARI_vs_labels\"]\n",
        "    )\n",
        "\n",
        "\n",
        "db_results = run_dbscan_sweep(X_std, y, eps_values=(0.5, 0.7, 0.9, 1.1))\n",
        "print(db_results)\n",
        "\n",
        "# Pick one eps that yields a small number of clusters\n",
        "chosen_eps = 0.7\n",
        "db = DBSCAN(eps=chosen_eps, min_samples=5)\n",
        "db_labels = db.fit_predict(X_std)\n",
        "\n",
        "df_pca[\"dbscan_label\"] = db_labels\n",
        "\n",
        "plt.figure()\n",
        "sns.scatterplot(\n",
        "    data=df_pca,\n",
        "    x=\"PC1\",\n",
        "    y=\"PC2\",\n",
        "    hue=\"dbscan_label\",\n",
        "    palette=\"tab10\",\n",
        "    alpha=0.8,\n",
        ")\n",
        "plt.title(f\"WDBC: DBSCAN Clusters in PCA Space (eps={chosen_eps})\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"wdbc_dbscan_pca_clusters.png\", dpi=300)\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "ytEZ_p1bGTa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Discriminant Analysis (LDA and QDA)"
      ],
      "metadata": {
        "id": "D7jQxXtpGXl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "ClLYKROzGasp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.1 LDA and QDA Pipelines (Full Feature Space)"
      ],
      "metadata": {
        "id": "tA-BVqyqGf7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda_pipe = Pipeline(\n",
        "    [\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"lda\", LinearDiscriminantAnalysis()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "qda_pipe = Pipeline(\n",
        "    [\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"qda\", QuadraticDiscriminantAnalysis()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "lda_pipe.fit(X_train, y_train)\n",
        "qda_pipe.fit(X_train, y_train)\n",
        "\n",
        "y_pred_lda = lda_pipe.predict(X_test)\n",
        "y_pred_qda = qda_pipe.predict(X_test)\n",
        "\n",
        "print(\"LDA accuracy:\", (y_pred_lda == y_test).mean())\n",
        "print(\"QDA accuracy:\", (y_pred_qda == y_test).mean())\n",
        "\n",
        "print(\"\\nLDA classification report:\")\n",
        "print(classification_report(y_test, y_pred_lda))\n",
        "\n",
        "print(\"QDA classification report:\")\n",
        "print(classification_report(y_test, y_pred_qda))\n",
        "\n",
        "# Confusion matrices\n",
        "def plot_confusion(cm, title, filename):\n",
        "    plt.figure()\n",
        "    sns.heatmap(\n",
        "        cm,\n",
        "        annot=True,\n",
        "        fmt=\"d\",\n",
        "        cmap=\"Blues\",\n",
        "        cbar=False,\n",
        "        xticklabels=[\"Benign\", \"Malignant\"],\n",
        "        yticklabels=[\"Benign\", \"Malignant\"],\n",
        "    )\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(FIG_DIR / filename, dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "cm_lda = confusion_matrix(y_test, y_pred_lda)\n",
        "cm_qda = confusion_matrix(y_test, y_pred_qda)\n",
        "\n",
        "plot_confusion(cm_lda, \"LDA Confusion Matrix (WDBC)\", \"wdbc_lda_confusion.png\")\n",
        "plot_confusion(cm_qda, \"QDA Confusion Matrix (WDBC)\", \"wdbc_qda_confusion.png\")"
      ],
      "metadata": {
        "id": "jkvHX6U9GiRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.2 Decision Boundaries in PCA Space\n",
        "#\n",
        "For visualization, we reduce features to two principal components and train\n",
        "LDA and QDA on this 2D representation."
      ],
      "metadata": {
        "id": "NgA_IhluGm_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA on full dataset\n",
        "pca2 = PCA(n_components=2, random_state=42)\n",
        "X_std_full = StandardScaler().fit_transform(X)\n",
        "X_pca2 = pca2.fit_transform(X_std_full)\n",
        "\n",
        "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(\n",
        "    X_pca2, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "lda_pca = LinearDiscriminantAnalysis()\n",
        "qda_pca = QuadraticDiscriminantAnalysis()\n",
        "\n",
        "lda_pca.fit(X_train_pca, y_train_pca)\n",
        "qda_pca.fit(X_train_pca, y_train_pca)\n",
        "\n",
        "# Grid for decision boundaries\n",
        "x_min, x_max = X_pca2[:, 0].min() - 1, X_pca2[:, 0].max() + 1\n",
        "y_min, y_max = X_pca2[:, 1].min() - 1, X_pca2[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(\n",
        "    np.linspace(x_min, x_max, 400),\n",
        "    np.linspace(y_min, y_max, 400),\n",
        ")\n",
        "grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "\n",
        "Z_lda = lda_pca.predict(grid).reshape(xx.shape)\n",
        "Z_qda = qda_pca.predict(grid).reshape(xx.shape)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "for ax, Z, title in zip(\n",
        "    axes,\n",
        "    [Z_lda, Z_qda],\n",
        "    [\"LDA Decision Regions (PC1-PC2)\", \"QDA Decision Regions (PC1-PC2)\"],\n",
        "):\n",
        "    ax.contourf(xx, yy, Z, alpha=0.3, cmap=\"Pastel1\")\n",
        "    scatter = ax.scatter(\n",
        "        X_train_pca[:, 0],\n",
        "        X_train_pca[:, 1],\n",
        "        c=y_train_pca,\n",
        "        cmap=\"Set1\",\n",
        "        edgecolor=\"k\",\n",
        "        alpha=0.8,\n",
        "    )\n",
        "    ax.set_xlabel(\"PC1\")\n",
        "    ax.set_ylabel(\"PC2\")\n",
        "    ax.set_title(title)\n",
        "\n",
        "handles, labels = scatter.legend_elements()\n",
        "fig.legend(handles, [\"Benign\", \"Malignant\"], title=\"Diagnosis\", loc=\"upper right\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"wdbc_lda_qda_decision_boundaries.png\", dpi=300)\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "0JvNXlaTGrQT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}