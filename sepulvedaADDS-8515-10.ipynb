{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V6E1",
      "authorship_tag": "ABX9TyNer1o6LXzz3iHWH7aqkS4q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alfredqbit/NU-DDS-8515/blob/main/sepulvedaADDS-8515-10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 10: Structural Equation Modeling with Holzinger–Swineford (1939)\n",
        "#\n",
        "This notebook implements the CFA and multi-group SEM analyses described in the LaTeX report.\n",
        "It uses the Holzinger–Swineford dataset, a three-factor model (visual, textual, speed), and examines approximate measurement invariance across schools."
      ],
      "metadata": {
        "id": "deMWXh1_PWiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "!pip install semopy\n",
        "from semopy import Model\n",
        "from semopy.stats import calc_stats\n",
        "from semopy.multigroup import multigroup\n",
        "\n",
        "# Ensure Figures directory exists\n",
        "FIG_DIR = Path(\"Figures\")\n",
        "FIG_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# A small utility for consistent plot saving\n",
        "def save_fig(fig, name: str, dpi: int = 300):\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(FIG_DIR / name, dpi=dpi, bbox_inches=\"tight\")\n",
        "    plt.close(fig)"
      ],
      "metadata": {
        "id": "DaDAkJ9DPdTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # 1. Data loading and preprocessing\n",
        "#\n",
        "We load a public CSV version of the Holzinger–Swineford dataset and align variable names with the standard `x1`–`x9` convention used in SEM examples."
      ],
      "metadata": {
        "id": "8QzG-uILPgmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_hs_data() -> pd.DataFrame:\n",
        "\n",
        "    # Load the Holzinger-Swineford 1939 data from a public GitHub URL and\n",
        "    # rename key columns to x1..x9 plus school and other background variables.\n",
        "\n",
        "    # Returns\n",
        "    # -------\n",
        "    # pd.DataFrame\n",
        "    #    Preprocessed dataframe.\n",
        "    # \"\"\"\n",
        "    url = (\n",
        "        \"https://github.com/cddesja/epsy8266/raw/master/\"\n",
        "        \"course_materials/data/HolzingerSwineford1939.csv\"\n",
        "    )\n",
        "    df = pd.read_csv(url)\n",
        "\n",
        "    # Rename to match the classic lavaan example as closely as possible\n",
        "    rename_map = {\n",
        "        \"visual\": \"x1\",\n",
        "        \"cubes\": \"x2\",\n",
        "        \"paper\": \"x3\",\n",
        "        \"paragrap\": \"x4\",\n",
        "        \"sentence\": \"x5\",\n",
        "        \"wordm\": \"x6\",\n",
        "        \"addition\": \"x7\",\n",
        "        \"counting\": \"x8\",\n",
        "        \"straight\": \"x9\",\n",
        "        \"agey\": \"ageyr\",\n",
        "        \"gender\": \"sex\"\n",
        "    }\n",
        "    df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})\n",
        "\n",
        "    # Keep only variables of interest plus school and background\n",
        "    cols = [\"id\", \"sex\", \"ageyr\", \"school\", \"grade\"] + [f\"x{i}\" for i in range(1, 10)]\n",
        "    df = df[cols]\n",
        "\n",
        "    # Drop rows with missing values on indicators\n",
        "    df = df.dropna(subset=[f\"x{i}\" for i in range(1, 10)])\n",
        "\n",
        "    # Ensure school is categorical\n",
        "    df[\"school\"] = df[\"school\"].astype(\"category\")\n",
        "\n",
        "    return df\n",
        "\n",
        "data = load_hs_data()\n",
        "data.head()\n",
        "\n",
        "def get_factor_scores(model, data_obs: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Compute factor scores for a fitted semopy Model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : semopy.Model (or subclass)\n",
        "        Fitted SEM model.\n",
        "    data_obs : pd.DataFrame\n",
        "        Data for the observed indicators only (no latent columns).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    scores : pd.DataFrame\n",
        "        Factor scores for each latent variable, one row per observation.\n",
        "    \"\"\"\n",
        "    # Preferred: dedicated factor-score method\n",
        "    if hasattr(model, \"predict_factors\"):\n",
        "        scores = model.predict_factors(data_obs)\n",
        "        # predict_factors already returns only latent variables\n",
        "        return scores\n",
        "\n",
        "    # Fallback: use general predict() & subset latent variables\n",
        "    preds = model.predict(data_obs)  # returns all variables\n",
        "    # Model stores latent variable names in model.vars['latent']\n",
        "    latent_vars = model.vars.get(\"latent\", [])\n",
        "    if not latent_vars:\n",
        "        # No latent variables? return empty frame with matching index\n",
        "        return pd.DataFrame(index=data_obs.index)\n",
        "\n",
        "    scores = preds[latent_vars].copy()\n",
        "    return scores"
      ],
      "metadata": {
        "id": "_nfk2c9ZPmOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Exploratory data analysis (EDA)\n",
        " We examine basic summaries and a correlation matrix for the nine indicators."
      ],
      "metadata": {
        "id": "45EQeV00Pqcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Summary statistics\n",
        "desc = data[[f\"x{i}\" for i in range(1, 10)]].describe().T\n",
        "desc\n",
        "\n",
        "# %%\n",
        "# Correlation heatmap for x1..x9\n",
        "\n",
        "# Create a mapping from internal 'x' names back to original descriptive names\n",
        "# This assumes the 'rename_map' logic from load_hs_data\n",
        "reverse_rename_map = {\n",
        "    \"x1\": \"visual\",\n",
        "    \"x2\": \"cubes\",\n",
        "    \"x3\": \"paper\",\n",
        "    \"x4\": \"paragraph\",\n",
        "    \"x5\": \"sentence\",\n",
        "    \"x6\": \"wordm\",\n",
        "    \"x7\": \"addition\",\n",
        "    \"x8\": \"counting\",\n",
        "    \"x9\": \"straight\"\n",
        "}\n",
        "\n",
        "# Select indicator columns and rename them for the heatmap\n",
        "indicator_cols = [f\"x{i}\" for i in range(1, 10)]\n",
        "df_for_corr = data[indicator_cols].rename(columns=reverse_rename_map)\n",
        "\n",
        "corr = df_for_corr.corr()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7, 6))\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", ax=ax)\n",
        "ax.set_title(\"Correlation Matrix: Holzinger–Swineford Indicators\")\n",
        "save_fig(fig, \"hs_corr_heatmap.png\")\n",
        "\n",
        "# %%\n",
        "# Histograms of indicators\n",
        "fig, axes = plt.subplots(3, 3, figsize=(9, 7))\n",
        "axes = axes.flatten()\n",
        "for i, ax in enumerate(axes, start=1):\n",
        "    sns.histplot(data[f\"x{i}\"], bins=20, kde=False, ax=ax)\n",
        "    ax.set_title(f\"x{i}\")\n",
        "plt.suptitle(\"Distributions of Cognitive Test Scores\", y=1.02)\n",
        "save_fig(fig, \"hs_histograms.png\")"
      ],
      "metadata": {
        "id": "cwI-ccvqPvXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. CFA model specification and single-group fit\n",
        "We use a three-factor CFA model:\n",
        "#\n",
        " ```text\n",
        " visual =~ x1 + x2 + x3\n",
        " textual =~ x4 + x5 + x6\n",
        " speed   =~ x7 + x8 + x9\n",
        "#\n",
        " visual ~~ textual\n",
        " visual ~~ speed\n",
        " textual ~~ speed"
      ],
      "metadata": {
        "id": "q-gmhFTlPz4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfa_model_desc = \"\"\"\n",
        "visual =~ x1 + x2 + x3\n",
        "textual =~ x4 + x5 + x6\n",
        "speed =~ x7 + x8 + x9\n",
        "\n",
        "visual ~~ textual\n",
        "visual ~~ speed\n",
        "textual ~~ speed\n",
        "\"\"\"\n",
        "\n",
        "model = Model(cfa_model_desc)\n",
        "res = model.fit(data[[f\"x{i}\" for i in range(1, 10)]])\n",
        "estimates = model.inspect(std_est=True)\n",
        "\n",
        "# Calculate fit statistics\n",
        "fit_stats = calc_stats(model)\n",
        "\n",
        "display(estimates.head())\n",
        "\n",
        "# Select a subset of fit indices you actually care about\n",
        "# (adjust column names if your semopy version differs)\n",
        "cols_to_show = [\n",
        "    \"DoF\",         # degrees of freedom\n",
        "    \"chi2\",       # chi-square\n",
        "    \"chi2 p-value\",    # p-value\n",
        "    \"CFI\",\n",
        "    \"TLI\",\n",
        "    \"RMSEA\",\n",
        "]\n",
        "\n",
        "# Ensure we only select columns that exist\n",
        "available_cols = [c for c in cols_to_show if c in fit_stats.columns]\n",
        "fit_subset = fit_stats[available_cols].copy()\n",
        "\n",
        "# Round for display\n",
        "cell_text = np.round(fit_subset.values, 3)\n",
        "col_labels = fit_subset.columns.tolist()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(9, 2.2))  # wider and a bit taller\n",
        "ax.axis(\"off\")\n",
        "\n",
        "tbl = ax.table(\n",
        "    cellText=cell_text,\n",
        "    colLabels=col_labels,\n",
        "    cellLoc=\"center\",\n",
        "    loc=\"center\",\n",
        ")\n",
        "\n",
        "# Control font and scaling to avoid overlap\n",
        "tbl.auto_set_font_size(False)\n",
        "tbl.set_fontsize(9)\n",
        "tbl.scale(1.2, 1.4)  # widen cells and increase row height\n",
        "\n",
        "# Optional: bold header row\n",
        "for (row, col), cell in tbl.get_celld().items():\n",
        "    if row == 0:\n",
        "        cell.set_text_props(weight=\"bold\")\n",
        "\n",
        "save_fig(fig, \"hs_fit_indices.png\")"
      ],
      "metadata": {
        "id": "jtG2Kxl3QE18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.1 Standardized factor loadings"
      ],
      "metadata": {
        "id": "b1sYphO-QQBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract standardized loadings\n",
        "loadings = estimates[\n",
        "    (estimates[\"op\"] == \"~\") &\n",
        "    (estimates[\"rval\"].isin([\"visual\", \"textual\", \"speed\"]))\n",
        "].copy()\n",
        "\n",
        "loadings = loadings[[\"lval\", \"rval\", \"Estimate\", \"Std. Err\", \"z-value\", \"p-value\", \"Est. Std\"]]\n",
        "loadings\n",
        "\n",
        "# %%\n",
        "# Plot standardized loadings by factor\n",
        "fig, ax = plt.subplots(figsize=(7, 4))\n",
        "for factor, group_df in loadings.groupby(\"rval\"):\n",
        "    ax.bar(\n",
        "        group_df[\"lval\"],\n",
        "        group_df[\"Est. Std\"],\n",
        "        label=factor,\n",
        "        alpha=0.7\n",
        "    )\n",
        "\n",
        "ax.set_ylabel(\"Standardized loading\")\n",
        "ax.set_title(\"Standardized Factor Loadings by Latent Ability\")\n",
        "ax.axhline(0, color=\"black\", linewidth=0.8)\n",
        "ax.legend()\n",
        "save_fig(fig, \"hs_factor_loadings.png\")"
      ],
      "metadata": {
        "id": "UGVTVEE9QTfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2 Factor scores"
      ],
      "metadata": {
        "id": "9UhYeCA-QXTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict factor scores\n",
        "# Indicators used in the CFA\n",
        "indicator_cols = [f\"x{i}\" for i in range(1, 10)]\n",
        "X_ind = data[indicator_cols]\n",
        "\n",
        "# Factor scores via helper (handles both modern and older semopy versions)\n",
        "factor_scores = get_factor_scores(model, X_ind)\n",
        "\n",
        "# Attach school/group labels for plotting\n",
        "factor_scores[\"school\"] = data[\"school\"].values\n",
        "\n",
        "# Example scatter: visual vs textual, color = school\n",
        "fig, ax = plt.subplots(figsize=(6, 5))\n",
        "sns.scatterplot(\n",
        "    data=factor_scores,\n",
        "    x=\"visual\",\n",
        "    y=\"textual\",\n",
        "    hue=\"school\",\n",
        "    alpha=0.7,\n",
        "    ax=ax\n",
        ")\n",
        "ax.set_title(\"Factor Scores: Visual vs Textual by School\")\n",
        "save_fig(fig, \"hs_factor_scores.png\")"
      ],
      "metadata": {
        "id": "KdSIFi6GQaT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Multi-group CFA by school\n",
        "#\n",
        "We examine configural invariance (same pattern of loadings) and approximate metric\n",
        "invariance (similar loadings across schools) using group-specific fits."
      ],
      "metadata": {
        "id": "nTG00bIAQeeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "schools = data[\"school\"].cat.categories.tolist()\n",
        "group_dfs = {g: data.loc[data[\"school\"] == g, [f\"x{i}\" for i in range(1, 10)]] for g in schools}\n",
        "\n",
        "# Fit same model separately by school\n",
        "group_models = {}\n",
        "group_loadings = []\n",
        "\n",
        "for g, df_g in group_dfs.items():\n",
        "    m_g = Model(cfa_model_desc)\n",
        "    m_g.fit(df_g)\n",
        "    est_g = m_g.inspect(std_est=True)\n",
        "    group_models[g] = m_g\n",
        "\n",
        "    l_g = est_g[\n",
        "        (est_g[\"op\"] == \"~\") &\n",
        "        (est_g[\"rval\"].isin([\"visual\", \"textual\", \"speed\"]))\n",
        "    ].copy()\n",
        "    l_g[\"school\"] = g\n",
        "    group_loadings.append(l_g)\n",
        "\n",
        "group_loadings = pd.concat(group_loadings, ignore_index=True)\n",
        "\n",
        "# %%\n",
        "# Compare standardized loadings across schools\n",
        "group_loadings_pivot = group_loadings.pivot_table(\n",
        "    index=[\"lval\", \"rval\"],\n",
        "    columns=\"school\",\n",
        "    values=\"Est. Std\"\n",
        ")\n",
        "group_loadings_pivot\n",
        "\n",
        "# %%\n",
        "# Plot multi-group loadings\n",
        "fig, axes = plt.subplots(1, 3, figsize=(12, 4), sharey=True)\n",
        "for ax, factor in zip(axes, [\"visual\", \"textual\", \"speed\"]):\n",
        "    df_f = group_loadings[group_loadings[\"rval\"] == factor]\n",
        "    sns.barplot(\n",
        "        data=df_f,\n",
        "        x=\"lval\",\n",
        "        y=\"Est. Std\",\n",
        "        hue=\"school\",\n",
        "        ax=ax\n",
        "    )\n",
        "    ax.set_title(f\"{factor.capitalize()} loadings\")\n",
        "    ax.set_ylim(0, 1.2)\n",
        "\n",
        "fig.suptitle(\"Standardized Factor Loadings by School\")\n",
        "save_fig(fig, \"hs_multigroup_loadings.png\")\n",
        "\n",
        "group_factor_scores = []\n",
        "\n",
        "for g, df_g in group_dfs.items():  # group_dfs: dict school -> DataFrame\n",
        "    m_g = group_models[g]          # fitted Model for that school\n",
        "    fs_g = get_factor_scores(m_g, df_g)\n",
        "    fs_g[\"school\"] = g\n",
        "    group_factor_scores.append(fs_g)\n",
        "\n",
        "group_factor_scores = pd.concat(group_factor_scores, ignore_index=True)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 5))\n",
        "sns.scatterplot(\n",
        "    data=group_factor_scores,\n",
        "    x=\"visual\",\n",
        "    y=\"textual\",\n",
        "    hue=\"school\",\n",
        "    alpha=0.7,\n",
        "    ax=ax\n",
        ")\n",
        "ax.set_title(\"Multi-group Factor Scores: Visual vs Textual\")\n",
        "save_fig(fig, \"hs_multigroup_factor_scores2.png\")"
      ],
      "metadata": {
        "id": "NOzbt2nPQijQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 5. Residual diagnostics and approximate modification guidance\n",
        "#\n",
        "We inspect residual covariances and standardized residuals to identify potential localized misfit (informally analogous to high modification indices).\n"
      ],
      "metadata": {
        "id": "1cROjUmfQoIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Residual covariance matrix\n",
        "mx = model.inspect(mode=\"mx\", what=\"est\")\n",
        "\n",
        "# Manually construct Sigma_hat using the matrices from mx\n",
        "Lambda = mx['Lambda'].values\n",
        "Psi = mx['Psi'].values\n",
        "Theta = mx['Theta'].values\n",
        "\n",
        "sigma_hat = Lambda @ Psi @ Lambda.T + Theta\n",
        "\n",
        "S = np.cov(data[[f\"x{i}\" for i in range(1, 10)]].T, ddof=1)\n",
        "\n",
        "resid = S - sigma_hat\n",
        "resid_df = pd.DataFrame(\n",
        "    resid,\n",
        "    index=[f\"x{i}\" for i in range(1, 10)],\n",
        "    columns=[f\"x{i}\" for i in range(1, 10)]\n",
        ")\n",
        "resid_df\n",
        "\n",
        "# %%\n",
        "# Heatmap of residual covariances\n",
        "fig, ax = plt.subplots(figsize=(7, 6))\n",
        "sns.heatmap(resid_df, annot=False, cmap=\"coolwarm\", center=0, ax=ax)\n",
        "ax.set_title(\"Residual Covariance Matrix\")\n",
        "save_fig(fig, \"hs_residual_covariances.png\")"
      ],
      "metadata": {
        "id": "YB0gbVq5QsKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could flag the largest absolute residuals as candidates for model revision\n",
        "(e.g., allowing correlated residuals between specific indicators), but we do not\n",
        "modify the model further in order to avoid overfitting.\n",
        "\n",
        "# 6. Summary\n",
        "This notebook implements a three-factor CFA model for the Holzinger–Swineford data,evaluates global fit, inspects factor loadings and scores, and examines approximate measurement invariance across schools. All key figures are saved to the `Figures/` directory for inclusion in the LaTeX report."
      ],
      "metadata": {
        "id": "bfwSE782Qv-P"
      }
    }
  ]
}