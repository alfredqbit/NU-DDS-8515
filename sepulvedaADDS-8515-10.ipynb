{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxdDccqVFnQHD5Y90aBDnp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alfredqbit/NU-DDS-8515/blob/main/sepulvedaADDS-8515-10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Structural Equation Modeling with Holzinger–Swineford (1939)\n",
        "#\n",
        "This notebook implements the CFA and multi-group SEM analyses described in the LaTeX report.\n",
        "It uses the Holzinger–Swineford dataset, a three-factor model (visual, textual, speed), and examines approximate measurement invariance across schools."
      ],
      "metadata": {
        "id": "deMWXh1_PWiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# !pip install --upgrade --force-reinstall semopy # Force reinstallation to fix ModuleNotFoundError\n",
        "from semopy import Model\n",
        "from semopy.stats import calc_stats\n",
        "from semopy.scores import calc_scores # This import relies on semopy.scores existing\n",
        "from semopy.multigroup import multigroup\n",
        "\n",
        "# Ensure Figures directory exists\n",
        "FIG_DIR = Path(\"Figures\")\n",
        "FIG_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# A small utility for consistent plot saving\n",
        "def save_fig(fig, name: str, dpi: int = 300):\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(FIG_DIR / name, dpi=dpi, bbox_inches=\"tight\")\n",
        "    plt.close(fig)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "DaDAkJ9DPdTq",
        "outputId": "302811d9-4696-4b7e-f111-d5df16537885"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'semopy.scores'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-46206979.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msemopy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msemopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcalc_stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msemopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcalc_scores\u001b[0m \u001b[0;31m# This import relies on semopy.scores existing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msemopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultigroup\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultigroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'semopy.scores'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # 1. Data loading and preprocessing\n",
        "#\n",
        "We load a public CSV version of the Holzinger–Swineford dataset and align variable names with the standard `x1`–`x9` convention used in SEM examples."
      ],
      "metadata": {
        "id": "8QzG-uILPgmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_hs_data() -> pd.DataFrame:\n",
        "\n",
        "    # Load the Holzinger-Swineford 1939 data from a public GitHub URL and\n",
        "    # rename key columns to x1..x9 plus school and other background variables.\n",
        "\n",
        "    # Returns\n",
        "    # -------\n",
        "    # pd.DataFrame\n",
        "    #    Preprocessed dataframe.\n",
        "    # \"\"\"\n",
        "    url = (\n",
        "        \"https://github.com/cddesja/epsy8266/raw/master/\"\n",
        "        \"course_materials/data/HolzingerSwineford1939.csv\"\n",
        "    )\n",
        "    df = pd.read_csv(url)\n",
        "\n",
        "    # Rename to match the classic lavaan example as closely as possible\n",
        "    rename_map = {\n",
        "        \"visual\": \"x1\",\n",
        "        \"cubes\": \"x2\",\n",
        "        \"paper\": \"x3\",\n",
        "        \"paragrap\": \"x4\",\n",
        "        \"sentence\": \"x5\",\n",
        "        \"wordm\": \"x6\",\n",
        "        \"addition\": \"x7\",\n",
        "        \"counting\": \"x8\",\n",
        "        \"straight\": \"x9\",\n",
        "        \"agey\": \"ageyr\",\n",
        "        \"gender\": \"sex\"\n",
        "    }\n",
        "    df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})\n",
        "\n",
        "    # Keep only variables of interest plus school and background\n",
        "    cols = [\"id\", \"sex\", \"ageyr\", \"school\", \"grade\"] + [f\"x{i}\" for i in range(1, 10)]\n",
        "    df = df[cols]\n",
        "\n",
        "    # Drop rows with missing values on indicators\n",
        "    df = df.dropna(subset=[f\"x{i}\" for i in range(1, 10)])\n",
        "\n",
        "    # Ensure school is categorical\n",
        "    df[\"school\"] = df[\"school\"].astype(\"category\")\n",
        "\n",
        "    return df\n",
        "\n",
        "data = load_hs_data()\n",
        "data.head()"
      ],
      "metadata": {
        "id": "_nfk2c9ZPmOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Exploratory data analysis (EDA)\n",
        " We examine basic summaries and a correlation matrix for the nine indicators."
      ],
      "metadata": {
        "id": "45EQeV00Pqcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics\n",
        "desc = data[[f\"x{i}\" for i in range(1, 10)]].describe().T\n",
        "desc\n",
        "\n",
        "# %%\n",
        "# Correlation heatmap for x1..x9\n",
        "corr = data[[f\"x{i}\" for i in range(1, 10)]].corr()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7, 6))\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", ax=ax)\n",
        "ax.set_title(\"Correlation Matrix: Holzinger–Swineford Indicators\")\n",
        "save_fig(fig, \"hs_corr_heatmap.png\")\n",
        "\n",
        "# %%\n",
        "# Histograms of indicators\n",
        "fig, axes = plt.subplots(3, 3, figsize=(9, 7))\n",
        "axes = axes.flatten()\n",
        "for i, ax in enumerate(axes, start=1):\n",
        "    sns.histplot(data[f\"x{i}\"], bins=20, kde=False, ax=ax)\n",
        "    ax.set_title(f\"x{i}\")\n",
        "plt.suptitle(\"Distributions of Cognitive Test Scores\", y=1.02)\n",
        "save_fig(fig, \"hs_histograms.png\")"
      ],
      "metadata": {
        "id": "cwI-ccvqPvXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. CFA model specification and single-group fit\n",
        "We use a three-factor CFA model:\n",
        "#\n",
        " ```text\n",
        " visual =~ x1 + x2 + x3\n",
        " textual =~ x4 + x5 + x6\n",
        " speed   =~ x7 + x8 + x9\n",
        "#\n",
        " visual ~~ textual\n",
        " visual ~~ speed\n",
        " textual ~~ speed"
      ],
      "metadata": {
        "id": "q-gmhFTlPz4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfa_model_desc = \"\"\"\n",
        "visual =~ x1 + x2 + x3\n",
        "textual =~ x4 + x5 + x6\n",
        "speed =~ x7 + x8 + x9\n",
        "\n",
        "visual ~~ textual\n",
        "visual ~~ speed\n",
        "textual ~~ speed\n",
        "\"\"\"\n",
        "\n",
        "model = Model(cfa_model_desc)\n",
        "res = model.fit(data[[f\"x{i}\" for i in range(1, 10)]])\n",
        "estimates = model.inspect(std_est=True)\n",
        "estimates.head()\n",
        "\n",
        "# %%\n",
        "# Fit indices\n",
        "fit_stats = calc_stats(model)\n",
        "fit_stats\n",
        "\n",
        "# %%\n",
        "# Export fit indices table as an image\n",
        "fig, ax = plt.subplots(figsize=(4, 1.5))\n",
        "ax.axis(\"off\")\n",
        "tbl = ax.table(\n",
        "    cellText=np.round(fit_stats.values, 4),\n",
        "    colLabels=fit_stats.columns,\n",
        "    loc=\"center\"\n",
        ")\n",
        "tbl.auto_set_font_size(False)\n",
        "tbl.set_fontsize(8)\n",
        "tbl.scale(1.2, 1.2)\n",
        "save_fig(fig, \"hs_fit_indices.png\")"
      ],
      "metadata": {
        "id": "jtG2Kxl3QE18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.1 Standardized factor loadings"
      ],
      "metadata": {
        "id": "b1sYphO-QQBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract standardized loadings\n",
        "loadings = estimates[\n",
        "    (estimates[\"op\"] == \"~\") &\n",
        "    (estimates[\"rval\"].isin([\"visual\", \"textual\", \"speed\"]))\n",
        "].copy()\n",
        "\n",
        "loadings = loadings[[\"lval\", \"rval\", \"Estimate\", \"Std. Err\", \"z-value\", \"p-value\", \"Est. Std\"]]\n",
        "loadings\n",
        "\n",
        "# %%\n",
        "# Plot standardized loadings by factor\n",
        "fig, ax = plt.subplots(figsize=(7, 4))\n",
        "for factor, group_df in loadings.groupby(\"rval\"):\n",
        "    ax.bar(\n",
        "        group_df[\"lval\"],\n",
        "        group_df[\"Est. Std\"],\n",
        "        label=factor,\n",
        "        alpha=0.7\n",
        "    )\n",
        "\n",
        "ax.set_ylabel(\"Standardized loading\")\n",
        "ax.set_title(\"Standardized Factor Loadings by Latent Ability\")\n",
        "ax.axhline(0, color=\"black\", linewidth=0.8)\n",
        "ax.legend()\n",
        "save_fig(fig, \"hs_factor_loadings.png\")"
      ],
      "metadata": {
        "id": "UGVTVEE9QTfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2 Factor scores"
      ],
      "metadata": {
        "id": "9UhYeCA-QXTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict factor scores\n",
        "factor_scores = calc_scores(model, data[[f\"x{i}\" for i in range(1, 10)]]) # Call calc_scores directly\n",
        "factor_scores[\"school\"] = data[\"school\"].values\n",
        "\n",
        "# Scatter: visual vs textual\n",
        "fig, ax = plt.subplots(figsize=(6, 5))\n",
        "sns.scatterplot(\n",
        "    data=factor_scores,\n",
        "    x=\"visual\",\n",
        "    y=\"textual\",\n",
        "    hue=\"school\",\n",
        "    alpha=0.7,\n",
        "    ax=ax\n",
        ")\n",
        "ax.set_title(\"Factor Scores: Visual vs Textual by School\")\n",
        "save_fig(fig, \"hs_factor_scores.png\")"
      ],
      "metadata": {
        "id": "KdSIFi6GQaT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Multi-group CFA by school\n",
        "#\n",
        "We examine configural invariance (same pattern of loadings) and approximate metric\n",
        "invariance (similar loadings across schools) using group-specific fits."
      ],
      "metadata": {
        "id": "nTG00bIAQeeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "schools = data[\"school\"].cat.categories.tolist()\n",
        "group_dfs = {g: data.loc[data[\"school\"] == g, [f\"x{i}\" for i in range(1, 10)]] for g in schools}\n",
        "\n",
        "# Fit same model separately by school\n",
        "group_models = {}\n",
        "group_loadings = []\n",
        "\n",
        "for g, df_g in group_dfs.items():\n",
        "    m_g = Model(cfa_model_desc)\n",
        "    m_g.fit(df_g)\n",
        "    est_g = m_g.inspect(std_est=True)\n",
        "    group_models[g] = m_g\n",
        "\n",
        "    l_g = est_g[\n",
        "        (est_g[\"op\"] == \"~\") &\n",
        "        (est_g[\"rval\"].isin([\"visual\", \"textual\", \"speed\"]))\n",
        "    ].copy()\n",
        "    l_g[\"school\"] = g\n",
        "    group_loadings.append(l_g)\n",
        "\n",
        "group_loadings = pd.concat(group_loadings, ignore_index=True)\n",
        "\n",
        "# %%\n",
        "# Compare standardized loadings across schools\n",
        "group_loadings_pivot = group_loadings.pivot_table(\n",
        "    index=[\"lval\", \"rval\"],\n",
        "    columns=\"school\",\n",
        "    values=\"Std.Est\"\n",
        ")\n",
        "group_loadings_pivot\n",
        "\n",
        "# %%\n",
        "# Plot multi-group loadings\n",
        "fig, axes = plt.subplots(1, 3, figsize=(12, 4), sharey=True)\n",
        "for ax, factor in zip(axes, [\"visual\", \"textual\", \"speed\"]):\n",
        "    df_f = group_loadings[group_loadings[\"rval\"] == factor]\n",
        "    sns.barplot(\n",
        "        data=df_f,\n",
        "        x=\"lval\",\n",
        "        y=\"Std.Est\",\n",
        "        hue=\"school\",\n",
        "        ax=ax\n",
        "    )\n",
        "    ax.set_title(f\"{factor.capitalize()} loadings\")\n",
        "    ax.set_ylim(0, 1.2)\n",
        "\n",
        "fig.suptitle(\"Standardized Factor Loadings by School\")\n",
        "save_fig(fig, \"hs_multigroup_loadings.png\")"
      ],
      "metadata": {
        "id": "NOzbt2nPQijQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 5. Residual diagnostics and approximate modification guidance\n",
        "#\n",
        "We inspect residual covariances and standardized residuals to identify potential localized misfit (informally analogous to high modification indices).\n"
      ],
      "metadata": {
        "id": "1cROjUmfQoIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Residual covariance matrix\n",
        "mx = model.inspect(mode=\"mx\", what=\"est\")\n",
        "sigma_hat = mx[\"Sigma\"]  # implied covariance matrix\n",
        "S = np.cov(data[[f\"x{i}\" for i in range(1, 10)]].T, ddof=1)\n",
        "\n",
        "resid = S - sigma_hat\n",
        "resid_df = pd.DataFrame(\n",
        "    resid,\n",
        "    index=[f\"x{i}\" for i in range(1, 10)],\n",
        "    columns=[f\"x{i}\" for i in range(1, 10)]\n",
        ")\n",
        "resid_df\n",
        "\n",
        "# %%\n",
        "# Heatmap of residual covariances\n",
        "fig, ax = plt.subplots(figsize=(7, 6))\n",
        "sns.heatmap(resid_df, annot=False, cmap=\"coolwarm\", center=0, ax=ax)\n",
        "ax.set_title(\"Residual Covariance Matrix\")\n",
        "save_fig(fig, \"hs_residual_covariances.png\")"
      ],
      "metadata": {
        "id": "YB0gbVq5QsKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could flag the largest absolute residuals as candidates for model revision\n",
        "(e.g., allowing correlated residuals between specific indicators), but we do not\n",
        "modify the model further in order to avoid overfitting.\n",
        "\n",
        "# 6. Summary\n",
        "This notebook implements a three-factor CFA model for the Holzinger–Swineford data,evaluates global fit, inspects factor loadings and scores, and examines approximate measurement invariance across schools. All key figures are saved to the `Figures/` directory for inclusion in the LaTeX report."
      ],
      "metadata": {
        "id": "bfwSE782Qv-P"
      }
    }
  ]
}